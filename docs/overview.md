# ðŸ§¬ CAFA-6 Protein Function Prediction â€” Overview

**Date:** 11 Dec 2025  
**Best validated baseline:** KNN + per-aspect thresholds â€” F1 = 0.2579 (MF=0.40, BP=0.20, CC=0.40)  
**Decision:** KNN alone is not competitive enough â†’ pivot to a CAFA5 Rank-1 style stack (modular Level-1 ensemble â†’ Level-2 GCN stacker â†’ strict GO post-processing).  
**Detailed execution:** `docs/PLAN.md`

---
## 1. Problem
Predict multi-label Gene Ontology (GO) terms for protein sequences across MF/BP/CC.  
Metric: IA-weighted F1, averaged over MF/BP/CC (per-aspect evaluation is mandatory).

---
## 2. Where we are (truth, not vibes)
- Validation + metric are now correct locally (MF/BP/CC split).
- KNN got us to F1=0.2579, but it plateaus: it transfers homology, not biology.
- Label propagation on KNN is counterproductive (noise gets amplified up the hierarchy).

---
## 3. New approach (what we are actually building)
**Core idea:** treat strong but diverse base predictors as feature generators, then let a GCN learn how to reconcile them using the GO graph.

### Phase 0 â€” Environments + config
Deliverables:
- Two environments: `rapids-env` (preproc + linear/GBDT) and `pytorch-env` (embeddings + GCN).
- Kaggle-first setup (single notebook) with paths and artefact directories.

### Phase 1 â€” Feature engineering at scale
Deliverables:
- Parsed sequences + targets in efficient formats.
- External GO annotations (especially electronic) parsed and hierarchy-propagated.
- Multimodal embeddings (core: T5 + ESM2-650M + ESM2-3B + Ankh + TF-IDF text + taxonomy).

### Phase 2 â€” Level-1 models (OOF features)
Deliverables:
- Out-of-fold (OOF) predictions for each base model (GBDTs + logistic regression + DNN ensemble).
- Test predictions for each base model.

### Phase 3 â€” Level-2 stacker (GCN per ontology)
Deliverables:
- Three GCNs (BP/MF/CC) trained on Level-1 OOF predictions.
- Test-time augmentation (TTA) predictions and averaged `pred.tsv`.

### Phase 4 â€” Strict post-processing + submission
Deliverables:
- Max-propagation + min-propagation over GO graph.
- Final `submission.tsv` that is hierarchy-consistent and format-valid.

---
## 4. Immediate next steps (implementation order)
1. Add `docs/PLAN.md` and align repo paths + artefact locations (Windows-friendly).
2. Decide the minimal â€œfirst runnable sliceâ€:
   - Start with (T5 + taxonomy) â†’ (logreg + small GBDT) â†’ (tiny GCN) â†’ (max-prop only).
3. Implement the data artefact pipeline (parse FASTA, build label matrices, IA weights).
4. Only then scale: more modalities, more base models, full GCN + TTA + min/max postproc.

---
## 4a. âœ… Progress checklist (single source of truth)
- [x] Data ingestion (FASTA, GO terms, ontology, taxonomy, IA weights)
- [x] Baseline: Frequency (per-aspect CAFA metric implemented)
- [x] Baseline: KNN (per-aspect CAFA metric implemented) â€” best F1=0.2579
- [x] Label propagation on KNN tested â€” failed (amplifies errors)
- [x] CAFA5-style stacker prototype notebook exists (`notebooks/06_cafa5_style_stack.ipynb`)
- [x] Overview cleaned and pivoted to Rank-1 stack plan
- [x] Create `docs/PLAN.md` with end-to-end execution steps
- [x] Kaggle setup notebook added (`notebooks/CAFA6_Rank1_Solution.ipynb`)
- [x] Competition rules snapshot captured (`rules.md`)
- [x] Phase 0: verify Kaggle GPU and run notebook end-to-end
- [x] Phase 1: Data Structuring (FASTA -> Feather, OBO parsing, Priors)
- [x] Phase 1: generate multimodal embeddings (T5 + ESM2 implemented)
- [x] Phase 1: Taxonomy features implemented
- [x] Phase 1: external GO features (UniProt GAF - optional)
- [x] Local GOA precompute notebook + filtered artefact (`goa_filtered_iea.tsv.gz`)
- [x] Kaggle GOA artefact discovery hardened (auto-scan `/kaggle/input`; supports `.tsv` and `.tsv.gz`)
- [x] Phase 1: external GOA hierarchy propagation (IEA) + injected into GCN stacker inputs
- [x] Phase 2: train Level-1 models + save OOF predictions (IA-weighted DNN loss + IA-F1 threshold diagnostics)
- [x] Offline embedding generator supports ESM2-3B + Ankh + 10279D text (TF-IDF)
- [x] Optional: build `EntryID -> text` corpus from UniProt + PubMed (`scripts/03_build_entryid_text_from_uniprot_pubmed.py`)
- [x] Colab notebook: build `entryid_text.tsv` (UniProt + PubMed) (`notebooks/Colab_01_build_entryid_text_uniprot_pubmed.ipynb`)
- [x] Colab notebook: generate optional embeddings artefacts (`notebooks/Colab_02_generate_optional_embeddings.ipynb`)
- [x] Colab notebooks normalised to Jupyter schema (cell `metadata.id`, `metadata.language`, `nbformat` keys)
- [x] Colab notebook: single-file text + TF-IDF + solution handoff (`notebooks/Colab_03_text_plus_solution.ipynb`)
- [x] Colab notebook: all-in-one (solution + text corpus + TF-IDF inline, no script calls) (`notebooks/Colab_04_all_in_one.ipynb`)
- [x] Option B: strict mode + Kaggle API dataset publishing integrated into `Colab_04` (requires `KAGGLE_USERNAME` + `KAGGLE_KEY`)
- [x] Colab_04: artefact manifest diagnostics cell (sizes + Option B required artefacts sanity check)
- [x] Colab_04: Kaggle Dataset-backed milestone checkpointing (`STORE.pull()` + `STORE.push(stage, ...)`)
- [x] Colab_04: unified secrets getter (env â†’ Kaggle Secrets â†’ Colab `userdata`) for Kaggle creds + dataset ID
- [x] Runbook: resumable runs across Kaggle/Colab/local (`docs/RUNBOOK_CHECKPOINTS.md`)
- [x] Colab_04: clearer failure mode for checkpoint pull HTTP 403 (private/not-shared dataset guidance)
- [x] Colab_04: compact notebook formatting (remove accidental excessive blank lines)
- [x] Colab_04: removed markdown cells + clarified embeddings generator label
- [x] Colab_04: added CAFA_FORCE_REBUILD + improved Colab dataset discovery (CAFA_DATASET_ROOT)
- [x] Colab_04: Colab-only Kaggle API auto-download for competition files (CAFA_COLAB_AUTO_DOWNLOAD)
- [x] Colab_04: Colab competition download unzips via Python (no `kaggle --unzip`)
- [x] Colab_04: fix Cell 3 diagnostics plot syntax (smoke-check clean)
- [x] Colab_04: fail-fast FASTA readability checks after setup
- [x] Colab_04: checkpoint publishing uploads folders (--dir-mode zip)
- [x] Colab_04: checkpoint publishing skips unchanged stages (CAFA_CHECKPOINT_FORCE_PUSH)
- [x] Colab_04: fix GOA propagation ID matching (normalise UniProt headers)
- [x] Colab_04: resolve CAFA_FORCE_REBUILD from Kaggle Secrets
- [x] Colab_04: T5/ESM2 embedding stages push even when reusing existing artefacts
- [x] Colab_04: ESM2 cell generates ESM2-3B + Ankh (skip-if-exists + checkpoint push)
- [x] Colab_04: require ESM2-3B + Ankh + taxonomy (fail-fast if missing)
- [x] Colab_04: split Level-1 training into per-model cells + per-model checkpoint pushes
- [x] Colab_04: remove unused embedding-generator cell; TF-IDF run cell is self-contained
- [x] Colab_04: PubMed fetch hardened (sanitize invalid XML + retry/backoff + recursive batch split)
- [x] Colab_04: ProtT5 checkpoint pushes after train and after test (granular, crash-safe)
- [x] Colab_04: ESM2/ESM2-3B/Ankh checkpoint pushes after train and after test (granular, crash-safe)
- [x] Phase 2: add KNN as Level-1 model (OOF + test preds) and wire into GCN stacker
- [x] Colab_04: visual diagnostics for embeddings + Level-1 models (histograms + IA-F1 curves)
- [ ] Phase 3: train GCN stacker (BP/MF/CC) + TTA aggregation
- [ ] Phase 4: strict min/max propagation + final submission generation
