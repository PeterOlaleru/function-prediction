{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744fbf44",
      "metadata": {
        "id": "744fbf44",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Bootstrap repo into /content (safe even if re-run)\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "REPO_URL = os.environ.get('CAFA_REPO_GIT_URL', 'https://github.com/PeterOla/cafa-6-protein-function-prediction.git')\n",
        "REPO_DIR = Path(os.environ.get('CAFA_REPO_DIR', '/content/cafa-6-protein-function-prediction'))\n",
        "SAFE_CWD = Path('/content') if Path('/content').exists() else Path('/')\n",
        "\n",
        "def run(cmd: list[str]) -> None:\n",
        "    cmd_str = ' '.join(cmd)\n",
        "    print('+', cmd_str)\n",
        "    p = subprocess.run(cmd, text=True, capture_output=True, cwd=str(SAFE_CWD))\n",
        "    if p.stdout.strip():\n",
        "        print(p.stdout)\n",
        "    if p.stderr.strip():\n",
        "        print(p.stderr)\n",
        "    if p.returncode != 0:\n",
        "        raise RuntimeError(f'Command failed (exit={p.returncode}): {cmd_str}')\n",
        "\n",
        "os.chdir(SAFE_CWD)\n",
        "print('SAFE_CWD:', SAFE_CWD)\n",
        "print('REPO_URL:', REPO_URL)\n",
        "print('REPO_DIR:', REPO_DIR)\n",
        "\n",
        "if REPO_DIR.exists() and (REPO_DIR / '.git').is_dir():\n",
        "    run(['git', '-C', str(REPO_DIR), 'fetch', '--depth', '1', 'origin'])\n",
        "    run(['git', '-C', str(REPO_DIR), 'reset', '--hard', 'origin/HEAD'])\n",
        "else:\n",
        "    if REPO_DIR.exists():\n",
        "        shutil.rmtree(REPO_DIR, ignore_errors=True)\n",
        "    run(['git', 'clone', '--depth', '1', REPO_URL, str(REPO_DIR)])\n",
        "\n",
        "os.environ['CAFA_REPO_ROOT'] = str(REPO_DIR)\n",
        "os.chdir(REPO_DIR)\n",
        "print('CWD:', Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d6e4522",
      "metadata": {
        "id": "8d6e4522",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip -q install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61dcc25",
      "metadata": {
        "id": "b61dcc25",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Phase 1 (minimal): parse FASTA → feather (so downstream scripts can run)\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "\n",
        "artefacts_dir = Path('artefacts_local') / 'artefacts'\n",
        "parsed_dir = artefacts_dir / 'parsed'\n",
        "parsed_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_fasta = Path('Train/train_sequences.fasta')\n",
        "test_fasta = Path('Test/testsuperset.fasta')\n",
        "train_out = parsed_dir / 'train_seq.feather'\n",
        "test_out = parsed_dir / 'test_seq.feather'\n",
        "\n",
        "def fasta_to_feather(inp: Path, out: Path) -> None:\n",
        "    rows = []\n",
        "    for r in SeqIO.parse(str(inp), 'fasta'):\n",
        "        rows.append({'id': str(r.id), 'sequence': str(r.seq)})\n",
        "    df = pd.DataFrame(rows)\n",
        "    if df.empty:\n",
        "        raise RuntimeError(f'Parsed 0 sequences from {inp}')\n",
        "    out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    df.to_feather(out)\n",
        "    print('Wrote:', out, 'shape=', df.shape)\n",
        "\n",
        "if not train_out.exists():\n",
        "    print('Building:', train_out)\n",
        "    fasta_to_feather(train_fasta, train_out)\n",
        "else:\n",
        "    print('Exists:', train_out)\n",
        "\n",
        "if not test_out.exists():\n",
        "    print('Building:', test_out)\n",
        "    fasta_to_feather(test_fasta, test_out)\n",
        "else:\n",
        "    print('Exists:', test_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81710d84",
      "metadata": {
        "id": "81710d84",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# NCBI settings (recommended)\n",
        "import os\n",
        "os.environ['NCBI_EMAIL'] = os.environ.get('NCBI_EMAIL', 'your.email@example.com')\n",
        "# os.environ['NCBI_API_KEY'] = '...'  # optional\n",
        "print('NCBI_EMAIL:', os.environ.get('NCBI_EMAIL'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c51e6ef",
      "metadata": {
        "id": "0c51e6ef",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Build EntryID → text corpus (UniProt + PubMed abstracts)\n",
        "# Produces: artefacts_local/artefacts/external/entryid_text.tsv\n",
        "# Start small with --max-ids, then remove/raise it for a full run.\n",
        "!python scripts/03_build_entryid_text_from_uniprot_pubmed.py --max-ids 1000 --max-pubmed-per-protein 3 --strip-go --sleep-uniprot 0.1 --sleep-pubmed 0.34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8b24e21",
      "metadata": {
        "id": "f8b24e21",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Generate TF‑IDF embeddings (10279D) from entryid_text.tsv\n",
        "!python scripts/02_generate_optional_embeddings.py --mode text --text-path artefacts_local/artefacts/external/entryid_text.tsv --text-dim 10279"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82800779",
      "metadata": {
        "id": "82800779",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Optional: execute the solution notebook in this same runtime.\n",
        "# If it is Kaggle-specific, it may need path tweaks before it will run on Colab.\n",
        "# Uncomment to run:\n",
        "# !jupyter nbconvert --to notebook --execute notebooks/CAFA6_Rank1_Solution.ipynb --output /content/CAFA6_Rank1_Solution.executed.ipynb\n",
        "print('Ready: corpus + TF‑IDF are built. Run your solution next.')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
