{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a537352",
        "language": "markdown"
      },
      "source": [
        "# CAFA6 — Build EntryID → Text Corpus (UniProt + PubMed)\n",
        "\n",
        "Produces `artefacts_local/artefacts/external/entryid_text.tsv` for the TF-IDF text modality (10279D).\n",
        "\n",
        "Notes:\n",
        "- This step is network/CPU bound; GPU doesn’t matter.\n",
        "- If you’re running on a remote runtime (e.g. Colab), the repo must exist on that runtime’s filesystem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bc9e197",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Colab bootstrap: get the repo onto this runtime (/content)\n",
        "# If you are running in VS Code attached to a Colab kernel, this is required\n",
        "# because your local Windows filesystem is NOT visible on the Colab VM.\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "REPO_URL = 'https://github.com/PeterOla/cafa-6-protein-function-prediction.git'\n",
        "REPO_DIR = Path('/content/cafa-6-protein-function-prediction')\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    print('Cloning repo into:', REPO_DIR)\n",
        "    !git clone --depth 1 {REPO_URL} {REPO_DIR}\n",
        "else:\n",
        "    print('Repo already present:', REPO_DIR)\n",
        "\n",
        "os.environ['CAFA_REPO_ROOT'] = str(REPO_DIR)\n",
        "os.chdir(REPO_DIR)\n",
        "print('CAFA_REPO_ROOT:', os.environ.get('CAFA_REPO_ROOT'))\n",
        "print('CWD:', Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bc0b4f1",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Resolve and validate repo root\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "repo_root = Path(os.environ.get('CAFA_REPO_ROOT', '/content/cafa-6-protein-function-prediction'))\n",
        "if not ((repo_root / 'requirements.txt').is_file() and (repo_root / 'scripts').is_dir()):\n",
        "    raise FileNotFoundError(\n",
        "        f'Repo root not found at {repo_root}. '\n",
        "        'Run the previous bootstrap cell (git clone), or set CAFA_REPO_ROOT.'\n",
        "    )\n",
        "\n",
        "os.chdir(repo_root)\n",
        "print('Repo root:', repo_root)\n",
        "print('CWD:', Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "286a1cb7",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Path diagnostics: what does this runtime actually see?\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Executable:', sys.executable)\n",
        "print('CWD:', Path.cwd())\n",
        "\n",
        "candidates = [\n",
        "    Path.cwd(),\n",
        "    Path.home(),\n",
        "    Path.home() / 'Documents',\n",
        "    Path('/content'),\n",
        "    Path('/workspace'),\n",
        "    Path('/kaggle'),\n",
        "]\n",
        "\n",
        "for p in candidates:\n",
        "    try:\n",
        "        exists = p.exists()\n",
        "    except Exception:\n",
        "        exists = False\n",
        "    print(f'-- {p} (exists={exists})')\n",
        "    if exists and p.is_dir():\n",
        "        try:\n",
        "            children = sorted([c.name for c in p.iterdir()])[:50]\n",
        "            print('   children[0:50]:', children)\n",
        "        except Exception as e:\n",
        "            print('   listdir error:', repr(e))\n",
        "\n",
        "print('CAFA_REPO_ROOT env:', os.environ.get('CAFA_REPO_ROOT'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6cb10ad",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Install dependencies (skip if your kernel already has them)\n",
        "%pip -q install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a47a7589",
        "language": "markdown"
      },
      "source": [
        "## Configure NCBI settings\n",
        "NCBI recommends supplying a contact email. If you have an NCBI API key, set it too (higher rate limits)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05b1ec0b",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['NCBI_EMAIL'] = 'Olalerupeter@gmail.com'  # change if needed\n",
        "# os.environ['NCBI_API_KEY'] = '...'  # optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaf1d9ea",
        "language": "markdown"
      },
      "source": [
        "## Build corpus\n",
        "Tip: start with `--max-ids 1000` to validate end-to-end, then remove it for full scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d915fd6f",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Build EntryID -> text corpus (UniProt + PubMed abstracts)\n",
        "# Produces: artefacts_local/artefacts/external/entryid_text.tsv\n",
        "!python scripts/03_build_entryid_text_from_uniprot_pubmed.py --max-ids 1000 --max-pubmed-per-protein 3 --strip-go --sleep-uniprot 0.1 --sleep-pubmed 0.34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e346d6c8",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Quick sanity check (won’t crash if the TSV isn’t produced yet)\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "p = Path('artefacts_local/artefacts/external/entryid_text.tsv')\n",
        "if not p.is_file():\n",
        "    print('Missing:', p)\n",
        "    ext_dir = p.parent\n",
        "    print('External dir exists:', ext_dir.exists(), ext_dir)\n",
        "    if ext_dir.exists():\n",
        "        print('External dir contents:', sorted([x.name for x in ext_dir.iterdir()])[:50])\n",
        "    print('Run the previous cell to build the corpus. If it failed, scroll that cell output.')\n",
        "else:\n",
        "    df = pd.read_csv(p, sep='\\t')\n",
        "    print('Shape:', df.shape)\n",
        "    print(df.head(3))\n",
        "    print('Non-empty text rows:', int((df['text'].fillna('').str.len() > 0).sum()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0d7d579",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Package output + caches (Windows-safe zip)\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "\n",
        "out_zip = Path('entryid_text_and_cache.zip')\n",
        "paths = [\n",
        "    Path('artefacts_local/artefacts/external/entryid_text.tsv'),\n",
        "    Path('artefacts_local/artefacts/external/uniprot_pubmed_cache'),\n",
        "]\n",
        "\n",
        "with zipfile.ZipFile(out_zip, 'w', compression=zipfile.ZIP_DEFLATED) as z:\n",
        "    for p in paths:\n",
        "        if p.is_file():\n",
        "            z.write(p, p.as_posix())\n",
        "        elif p.is_dir():\n",
        "            for fp in p.rglob('*'):\n",
        "                if fp.is_file():\n",
        "                    z.write(fp, fp.as_posix())\n",
        "\n",
        "print('Wrote:', out_zip.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5af0a897",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Optional: verify GPU (not required for this notebook)\n",
        "!nvidia-smi"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
