{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f5bd74",
   "metadata": {},
   "source": [
    "# EDA 02 – GO Ontology Deep Dive (BPO/MFO/CCO)\n",
    "\n",
    "Focus:\n",
    "- Split labels and terms by subontology (BPO, MFO, CCO)\n",
    "- Analyze IA distribution per ontology\n",
    "- Compare term rarity and IA weighting across namespaces\n",
    "- Identify most/least specific terms per branch\n",
    "- Visualize ontology hierarchy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0895c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import obonet\n",
    "from collections import Counter\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Paths\n",
    "TRAIN_TERMS = Path('Train/train_terms.tsv')\n",
    "GO_OBO = Path('Train/go-basic.obo')\n",
    "IA_TSV = Path('IA.tsv')\n",
    "\n",
    "FIG_DIR = Path('notebooks/figures')\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROC_DIR = Path('data/processed')\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Python:', sys.version)\n",
    "print('Paths ready:', [p.exists() for p in [TRAIN_TERMS, GO_OBO, IA_TSV]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2918e",
   "metadata": {},
   "source": [
    "## 1. Load GO Graph and Extract Namespace Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f894cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GO ontology\n",
    "go_graph = obonet.read_obo(str(GO_OBO))\n",
    "print('Nodes:', len(go_graph), '| Edges:', go_graph.number_of_edges())\n",
    "\n",
    "# Build term -> namespace mapping\n",
    "term_to_ns = {}\n",
    "ns_counts = Counter()\n",
    "for node, data in go_graph.nodes(data=True):\n",
    "    ns = data.get('namespace')\n",
    "    if ns:\n",
    "        term_to_ns[node] = ns\n",
    "        ns_counts[ns] += 1\n",
    "\n",
    "print('\\nNamespace distribution in GO graph:')\n",
    "for ns, cnt in ns_counts.most_common():\n",
    "    print(f'  {ns}: {cnt} terms')\n",
    "\n",
    "# Map full names\n",
    "NS_MAP = {\n",
    "    'biological_process': 'BPO',\n",
    "    'molecular_function': 'MFO',\n",
    "    'cellular_component': 'CCO'\n",
    "}\n",
    "term_to_ont = {t: NS_MAP.get(ns, ns) for t, ns in term_to_ns.items()}\n",
    "\n",
    "# Root terms\n",
    "ROOTS = {'BPO': 'GO:0008150', 'MFO': 'GO:0003674', 'CCO': 'GO:0005575'}\n",
    "print('\\nRoots present:', {k: v in go_graph for k, v in ROOTS.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ae9f6",
   "metadata": {},
   "source": [
    "## 2. Load Training Labels and Join with Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(TRAIN_TERMS, sep='\\t')\n",
    "print('Labels shape:', labels_df.shape)\n",
    "print('Unique proteins:', labels_df['EntryID'].nunique())\n",
    "print('Unique terms:', labels_df['term'].nunique())\n",
    "\n",
    "# Add ontology column\n",
    "labels_df['ontology'] = labels_df['term'].map(term_to_ont)\n",
    "missing_ont = labels_df['ontology'].isna().sum()\n",
    "if missing_ont:\n",
    "    print(f'Warning: {missing_ont} annotations with unknown ontology')\n",
    "\n",
    "labels_df = labels_df.dropna(subset=['ontology'])\n",
    "print('After drop NA ontology:', labels_df.shape)\n",
    "\n",
    "# Summary by ontology\n",
    "ont_summary = labels_df.groupby('ontology').agg(\n",
    "    proteins=('EntryID', 'nunique'),\n",
    "    terms=('term', 'nunique'),\n",
    "    annotations=('term', 'count')\n",
    ").reset_index()\n",
    "print('\\nPer-ontology summary:')\n",
    "display(ont_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead63399",
   "metadata": {},
   "source": [
    "## 3. Visualize Annotation Distribution by Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be59e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart: annotation shares\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].pie(ont_summary['annotations'], labels=ont_summary['ontology'], autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Annotation Share by Ontology')\n",
    "\n",
    "axes[1].pie(ont_summary['terms'], labels=ont_summary['ontology'], autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Unique Terms by Ontology')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'ontology_shares.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot: terms per protein by ontology\n",
    "terms_per_prot_ont = labels_df.groupby(['EntryID','ontology']).size().reset_index(name='count')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.boxplot(data=terms_per_prot_ont, x='ontology', y='count', ax=ax)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Terms per protein (log scale)')\n",
    "ax.set_title('Terms-per-protein distribution by ontology')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'terms_per_protein_by_ont.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96d935",
   "metadata": {},
   "source": [
    "## 4. Load IA Weights and Merge with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ia_df = pd.read_csv(IA_TSV, sep='\\t', header=None, names=['term','ia'])\n",
    "print('IA entries:', len(ia_df))\n",
    "print('IA stats:')\n",
    "display(ia_df['ia'].describe())\n",
    "\n",
    "# Add ontology to IA\n",
    "ia_df['ontology'] = ia_df['term'].map(term_to_ont)\n",
    "ia_df = ia_df.dropna(subset=['ontology'])\n",
    "\n",
    "# Merge term frequency from labels\n",
    "term_freq = labels_df['term'].value_counts().rename_axis('term').reset_index(name='freq')\n",
    "term_stats = term_freq.merge(ia_df, on='term', how='left')\n",
    "term_stats['log_freq'] = np.log10(term_stats['freq'] + 1)\n",
    "\n",
    "print('\\nTerm stats with IA:')\n",
    "display(term_stats.head(10))\n",
    "\n",
    "# Save for later use\n",
    "term_stats.to_csv(PROC_DIR / 'term_stats_with_ia.csv', index=False)\n",
    "print(f'Saved: {PROC_DIR / \"term_stats_with_ia.csv\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab0ab5",
   "metadata": {},
   "source": [
    "## 5. IA Distribution per Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IA histograms per ontology\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "for i, ont in enumerate(['BPO','MFO','CCO']):\n",
    "    subset = ia_df[ia_df['ontology'] == ont]\n",
    "    axes[i].hist(subset['ia'], bins=40, edgecolor='k', alpha=0.7)\n",
    "    axes[i].set_title(f'{ont} (n={len(subset)})')\n",
    "    axes[i].set_xlabel('IA')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Count')\n",
    "fig.suptitle('IA Distribution by Ontology', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'ia_by_ontology.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary stats\n",
    "ia_by_ont = ia_df.groupby('ontology')['ia'].describe()\n",
    "print('\\nIA stats by ontology:')\n",
    "display(ia_by_ont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d46b4e",
   "metadata": {},
   "source": [
    "## 6. IA vs Term Rarity (Frequency) per Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fca4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: log(freq) vs IA, faceted by ontology\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, ont in enumerate(['BPO','MFO','CCO']):\n",
    "    subset = term_stats[term_stats['ontology'] == ont].dropna(subset=['ia'])\n",
    "    axes[i].scatter(subset['log_freq'], subset['ia'], alpha=0.5, s=10)\n",
    "    axes[i].set_xlabel('log10(frequency + 1)')\n",
    "    axes[i].set_title(f'{ont} (n={len(subset)})')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('IA')\n",
    "    # Compute correlation\n",
    "    if len(subset) > 1:\n",
    "        from scipy.stats import spearmanr\n",
    "        rho, pval = spearmanr(subset['log_freq'], subset['ia'])\n",
    "        axes[i].text(0.05, 0.95, f'Spearman ρ={rho:.3f}\\np={pval:.2e}',\n",
    "                     transform=axes[i].transAxes, va='top', fontsize=10,\n",
    "                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "fig.suptitle('IA vs Term Frequency by Ontology', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'ia_vs_freq_by_ont.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7911c",
   "metadata": {},
   "source": [
    "## 7. Identify Most/Least Specific Terms per Ontology\n",
    "\n",
    "(Highest IA = most specific/informative; lowest IA = most general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ont in ['BPO','MFO','CCO']:\n",
    "    subset = term_stats[term_stats['ontology'] == ont].dropna(subset=['ia']).copy()\n",
    "    subset = subset.sort_values('ia', ascending=False)\n",
    "    print(f'\\n=== {ont} ===')\n",
    "    print('Top 10 most specific (highest IA):')\n",
    "    display(subset[['term','freq','ia']].head(10))\n",
    "    print('\\nTop 10 most general (lowest IA):')\n",
    "    display(subset[['term','freq','ia']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d919f",
   "metadata": {},
   "source": [
    "## 8. Compute Term Depth from Root (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3641c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute shortest path length from each term to its root\n",
    "def compute_depths(graph, root, namespace_filter=None):\n",
    "    \"\"\"Returns dict {term: depth} for terms reachable from root\"\"\"\n",
    "    if root not in graph:\n",
    "        return {}\n",
    "    lengths = nx.single_source_shortest_path_length(graph.reverse(), root)\n",
    "    if namespace_filter:\n",
    "        lengths = {t: d for t, d in lengths.items() \n",
    "                   if term_to_ont.get(t) == namespace_filter}\n",
    "    return lengths\n",
    "\n",
    "depth_dicts = {}\n",
    "for ont_short, root in ROOTS.items():\n",
    "    depth_dicts[ont_short] = compute_depths(go_graph, root, ont_short)\n",
    "    print(f'{ont_short}: {len(depth_dicts[ont_short])} terms with depth computed')\n",
    "\n",
    "# Merge depth into term_stats\n",
    "for ont in ['BPO','MFO','CCO']:\n",
    "    term_stats.loc[term_stats['ontology'] == ont, 'depth'] = \\\n",
    "        term_stats.loc[term_stats['ontology'] == ont, 'term'].map(depth_dicts[ont])\n",
    "\n",
    "print('\\nDepth distribution by ontology:')\n",
    "display(term_stats.groupby('ontology')['depth'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c7d7a",
   "metadata": {},
   "source": [
    "## 9. IA vs Depth Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: depth vs IA per ontology\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, ont in enumerate(['BPO','MFO','CCO']):\n",
    "    subset = term_stats[(term_stats['ontology'] == ont) & term_stats['depth'].notna() & term_stats['ia'].notna()]\n",
    "    axes[i].scatter(subset['depth'], subset['ia'], alpha=0.5, s=10)\n",
    "    axes[i].set_xlabel('Depth from root')\n",
    "    axes[i].set_title(f'{ont} (n={len(subset)})')\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('IA')\n",
    "    # Correlation\n",
    "    if len(subset) > 1:\n",
    "        from scipy.stats import pearsonr\n",
    "        r, pval = pearsonr(subset['depth'], subset['ia'])\n",
    "        axes[i].text(0.05, 0.95, f'Pearson r={r:.3f}\\np={pval:.2e}',\n",
    "                     transform=axes[i].transAxes, va='top', fontsize=10,\n",
    "                     bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "fig.suptitle('IA vs Depth by Ontology', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'ia_vs_depth_by_ont.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38222ec0",
   "metadata": {},
   "source": [
    "## 10. Visualize Sample Subgraph for Each Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dcef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each ontology, extract a small induced subgraph near root\n",
    "for ont_short, root in ROOTS.items():\n",
    "    if root not in go_graph:\n",
    "        continue\n",
    "    # Get descendants at depth <= 3\n",
    "    descendants = [n for n, d in depth_dicts[ont_short].items() if d <= 3]\n",
    "    if len(descendants) > 50:\n",
    "        descendants = descendants[:50]  # cap\n",
    "    subg = go_graph.subgraph(descendants)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(subg, seed=42, k=0.5)\n",
    "    nx.draw_networkx_nodes(subg, pos, node_size=50, node_color='lightblue')\n",
    "    nx.draw_networkx_edges(subg, pos, alpha=0.3, arrows=True, arrowsize=10)\n",
    "    # Label root only\n",
    "    labels = {root: root}\n",
    "    nx.draw_networkx_labels(subg, pos, labels, font_size=8)\n",
    "    plt.title(f'{ont_short} Sample Subgraph (depth ≤ 3, up to 50 nodes)')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f'go_subgraph_{ont_short}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6d7fc",
   "metadata": {},
   "source": [
    "## 11. Summary & Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Key findings:')\n",
    "print('- BPO, MFO, and CCO have distinct IA and frequency distributions')\n",
    "print('- IA generally increases with depth (more specific = higher IA)')\n",
    "print('- IA inversely correlates with term frequency (rare terms = high IA)')\n",
    "print('- Per-ontology modeling may capture namespace-specific patterns better')\n",
    "print('\\nNext steps:')\n",
    "print('- Build separate classifiers per ontology or multi-task heads')\n",
    "print('- Weight losses by IA to prioritize rare/specific terms')\n",
    "print('- Implement label propagation (child -> ancestors) for hierarchical consistency')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
