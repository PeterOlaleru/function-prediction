{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8338233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Local Detected\n",
      "DATASET_ROOT: c:\\Users\\Olale\\Documents\\Codebase\\Science\\cafa-6-protein-function-prediction\n",
      "All required inputs found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. SETUP, CONFIG & DIAGNOSTICS\n",
    "# ==========================================\n",
    "# HARDWARE: CPU (Standard)\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------------------\n",
    "# Environment Detection & Paths\n",
    "# ------------------------------------------\n",
    "IS_KAGGLE = os.getenv('KAGGLE_KERNEL_RUN_TYPE') is not None or Path('/kaggle').exists()\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print(\"Environment: Kaggle Detected\")\n",
    "    INPUT_ROOT = Path('/kaggle/input')\n",
    "    WORKING_ROOT = Path('/kaggle/working')\n",
    "    \n",
    "    # Standard Kaggle Input Listing\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "else:\n",
    "    print(\"Environment: Local Detected\")\n",
    "    # Robust Project Root Detection\n",
    "    CURRENT_DIR = Path.cwd()\n",
    "    if CURRENT_DIR.name == 'notebooks':\n",
    "        PROJECT_ROOT = CURRENT_DIR.parent\n",
    "    else:\n",
    "        PROJECT_ROOT = CURRENT_DIR\n",
    "        \n",
    "    INPUT_ROOT = PROJECT_ROOT\n",
    "    WORKING_ROOT = PROJECT_ROOT / 'artefacts_local'\n",
    "    WORKING_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "# Artefacts Directory\n",
    "ARTEFACTS_DIR = WORKING_ROOT / 'artefacts'\n",
    "ARTEFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(ARTEFACTS_DIR / 'parsed').mkdir(parents=True, exist_ok=True)\n",
    "(ARTEFACTS_DIR / 'features').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------\n",
    "# Dataset Discovery\n",
    "# ------------------------------------------\n",
    "DATASET_SLUG = 'cafa-6-protein-function-prediction'\n",
    "\n",
    "def find_dataset_root(input_root: Path, dataset_slug: str) -> Path:\n",
    "    # 1. Check for Kaggle slug\n",
    "    candidate = input_root / dataset_slug\n",
    "    if candidate.exists():\n",
    "        return candidate\n",
    "    \n",
    "    # 2. Check if we are already in the root (Local)\n",
    "    if (input_root / 'Train').exists():\n",
    "        return input_root\n",
    "\n",
    "    # 3. Fallback search\n",
    "    candidates = [p for p in input_root.iterdir() if p.is_dir()]\n",
    "    def score(p: Path) -> int:\n",
    "        return int((p / 'Train').exists()) + int((p / 'Test').exists())\n",
    "    candidates = sorted(candidates, key=score, reverse=True)\n",
    "    if candidates and score(candidates[0]) > 0:\n",
    "        return candidates[0]\n",
    "        \n",
    "    raise FileNotFoundError(f\"Dataset not found in {input_root}\")\n",
    "\n",
    "DATASET_ROOT = find_dataset_root(INPUT_ROOT, DATASET_SLUG)\n",
    "print(f\"DATASET_ROOT: {DATASET_ROOT}\")\n",
    "\n",
    "# Define Paths\n",
    "PATH_IA = DATASET_ROOT / 'IA.tsv'\n",
    "PATH_SAMPLE_SUB = DATASET_ROOT / 'sample_submission.tsv'\n",
    "PATH_TRAIN_FASTA = DATASET_ROOT / 'Train' / 'train_sequences.fasta'\n",
    "PATH_TRAIN_TERMS = DATASET_ROOT / 'Train' / 'train_terms.tsv'\n",
    "PATH_TRAIN_TAXON = DATASET_ROOT / 'Train' / 'train_taxonomy.tsv'\n",
    "PATH_GO_OBO = DATASET_ROOT / 'Train' / 'go-basic.obo'\n",
    "PATH_TEST_FASTA = DATASET_ROOT / 'Test' / 'testsuperset.fasta'\n",
    "PATH_TEST_TAXON = DATASET_ROOT / 'Test' / 'testsuperset-taxon-list.tsv'\n",
    "\n",
    "# ------------------------------------------\n",
    "# Sanity Checks\n",
    "# ------------------------------------------\n",
    "required = {\n",
    "    'IA.tsv': PATH_IA,\n",
    "    'Train/train_sequences.fasta': PATH_TRAIN_FASTA,\n",
    "    'Train/train_terms.tsv': PATH_TRAIN_TERMS,\n",
    "    'Train/go-basic.obo': PATH_GO_OBO,\n",
    "}\n",
    "missing = {k: v for k, v in required.items() if not v.exists()}\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing files: {missing}\")\n",
    "print(\"All required inputs found.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Initial Diagnostics (Sequence Lengths)\n",
    "# ------------------------------------------\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "def read_fasta_lengths(path: Path, max_records=20000):\n",
    "    lengths = []\n",
    "    current = 0\n",
    "    n = 0\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if n > 0: lengths.append(current)\n",
    "                n += 1\n",
    "                current = 0\n",
    "                if max_records and n > max_records: break\n",
    "            else:\n",
    "                current += len(line)\n",
    "        if n > 0: lengths.append(current)\n",
    "    return np.array(lengths)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.hist(read_fasta_lengths(PATH_TRAIN_FASTA), bins=50, alpha=0.5, label='Train')\n",
    "if PATH_TEST_FASTA.exists():\n",
    "    plt.hist(read_fasta_lengths(PATH_TEST_FASTA), bins=50, alpha=0.5, label='Test')\n",
    "plt.title('Sequence Length Distribution (First 20k)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe900118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing FASTA...\n",
      "FASTA parsed and saved to artefacts.\n",
      "Parsing OBO...\n",
      "FASTA parsed and saved to artefacts.\n",
      "Parsing OBO...\n",
      "GO Graph: 40119 nodes with parents, 48101 terms with namespace.\n",
      "GO Graph: 40119 nodes with parents, 48101 terms with namespace.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms processed and priors saved.\n",
      "Processing Taxonomy...\n",
      "Taxonomy processed. Train: 82404, Test: 224309\n",
      "Saving Targets & Term List...\n",
      "Taxonomy processed. Train: 82404, Test: 224309\n",
      "Saving Targets & Term List...\n",
      "Targets saved.\n",
      "Targets saved.\n"
     ]
    }
   ],
   "source": [
    "# 2. PHASE 1: DATA STRUCTURING & HIERARCHY\n",
    "# ==========================================\n",
    "# HARDWARE: CPU (Standard)\n",
    "# ==========================================\n",
    "\n",
    "# ------------------------------------------\n",
    "# A. Parse FASTA to Feather\n",
    "# ------------------------------------------\n",
    "def parse_fasta(path: Path) -> pd.DataFrame:\n",
    "    ids, seqs = [], []\n",
    "    cur_id, cur_seq = None, []\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if cur_id:\n",
    "                    ids.append(cur_id)\n",
    "                    seqs.append(''.join(cur_seq))\n",
    "                cur_id = line[1:].split()[0]\n",
    "                cur_seq = []\n",
    "            else:\n",
    "                cur_seq.append(line)\n",
    "        if cur_id:\n",
    "            ids.append(cur_id)\n",
    "            seqs.append(''.join(cur_seq))\n",
    "    return pd.DataFrame({'id': ids, 'sequence': seqs})\n",
    "\n",
    "print(\"Parsing FASTA...\")\n",
    "parse_fasta(PATH_TRAIN_FASTA).to_feather(ARTEFACTS_DIR / 'parsed' / 'train_seq.feather')\n",
    "if PATH_TEST_FASTA.exists():\n",
    "    parse_fasta(PATH_TEST_FASTA).to_feather(ARTEFACTS_DIR / 'parsed' / 'test_seq.feather')\n",
    "print(\"FASTA parsed and saved to artefacts.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# B. Parse OBO & Terms\n",
    "# ------------------------------------------\n",
    "def parse_obo(path: Path):\n",
    "    parents = {}\n",
    "    namespaces = {}\n",
    "    cur_id, cur_ns = None, None\n",
    "    with path.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == '[Term]':\n",
    "                if cur_id and cur_ns: namespaces[cur_id] = cur_ns\n",
    "                cur_id, cur_ns = None, None\n",
    "            elif line.startswith('id: GO:'):\n",
    "                cur_id = line.split('id: ', 1)[1]\n",
    "            elif line.startswith('namespace:'):\n",
    "                cur_ns = line.split('namespace: ', 1)[1]\n",
    "            elif line.startswith('is_a:') and cur_id:\n",
    "                parent = line.split('is_a: ', 1)[1].split(' ! ')[0]\n",
    "                if cur_id not in parents: parents[cur_id] = set()\n",
    "                parents[cur_id].add(parent)\n",
    "        if cur_id and cur_ns: namespaces[cur_id] = cur_ns\n",
    "    return parents, namespaces\n",
    "\n",
    "print(\"Parsing OBO...\")\n",
    "go_parents, go_namespaces = parse_obo(PATH_GO_OBO)\n",
    "print(f\"GO Graph: {len(go_parents)} nodes with parents, {len(go_namespaces)} terms with namespace.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# C. Process Terms & Priors\n",
    "# ------------------------------------------\n",
    "terms = pd.read_csv(PATH_TRAIN_TERMS, sep='\\t')\n",
    "col_term = terms.columns[1]\n",
    "terms['aspect'] = terms[col_term].map(lambda x: go_namespaces.get(x, 'UNK'))\n",
    "\n",
    "# Plot Aspects\n",
    "plt.figure(figsize=(6, 3))\n",
    "terms['aspect'].value_counts().plot(kind='bar', title='Annotations by Namespace')\n",
    "plt.show()\n",
    "\n",
    "# Save Priors\n",
    "priors = (terms[col_term].value_counts() / terms.iloc[:,0].nunique()).reset_index()\n",
    "priors.columns = ['term', 'prior']\n",
    "if PATH_IA.exists():\n",
    "    ia = pd.read_csv(PATH_IA, sep='\\t', names=['term', 'ia'])\n",
    "    priors = priors.merge(ia, on='term', how='left').fillna(0)\n",
    "priors.to_parquet(ARTEFACTS_DIR / 'parsed' / 'term_priors.parquet')\n",
    "print(\"Terms processed and priors saved.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# D. Process Taxonomy\n",
    "# ------------------------------------------\n",
    "print(\"Processing Taxonomy...\")\n",
    "# Train Taxonomy\n",
    "tax_train = pd.read_csv(PATH_TRAIN_TAXON, sep='\\t', header=None, names=['id', 'taxon_id'])\n",
    "tax_train['taxon_id'] = tax_train['taxon_id'].astype(int)\n",
    "tax_train.to_feather(ARTEFACTS_DIR / 'parsed' / 'train_taxa.feather')\n",
    "\n",
    "# Test Taxonomy (Extract from FASTA headers)\n",
    "if PATH_TEST_FASTA.exists():\n",
    "    ids, taxons = [], []\n",
    "    with PATH_TEST_FASTA.open('r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                parts = line[1:].split()\n",
    "                ids.append(parts[0])\n",
    "                # Assume second part is taxon if present\n",
    "                if len(parts) > 1:\n",
    "                    try:\n",
    "                        taxons.append(int(parts[1]))\n",
    "                    except ValueError:\n",
    "                        taxons.append(0)\n",
    "                else:\n",
    "                    taxons.append(0)\n",
    "    tax_test = pd.DataFrame({'id': ids, 'taxon_id': taxons})\n",
    "    tax_test.to_feather(ARTEFACTS_DIR / 'parsed' / 'test_taxa.feather')\n",
    "    print(f\"Taxonomy processed. Train: {len(tax_train)}, Test: {len(tax_test)}\")\n",
    "else:\n",
    "    print(f\"Taxonomy processed. Train: {len(tax_train)}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# E. Save Targets & Term List\n",
    "# ------------------------------------------\n",
    "print(\"Saving Targets & Term List...\")\n",
    "# Save full terms list (long format)\n",
    "terms.to_parquet(ARTEFACTS_DIR / 'parsed' / 'train_terms.parquet')\n",
    "\n",
    "# Save unique term list with counts\n",
    "term_counts = terms['term'].value_counts().reset_index()\n",
    "term_counts.columns = ['term', 'count']\n",
    "term_counts.to_parquet(ARTEFACTS_DIR / 'parsed' / 'term_counts.parquet')\n",
    "print(\"Targets saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping External Data (PROCESS_EXTERNAL=False).\n",
      "To implement Rank 1 fully, set PROCESS_EXTERNAL=True and ensure sufficient disk space.\n"
     ]
    }
   ],
   "source": [
    "# 2.1 PHASE 1 (Step 3): EXTERNAL DATA & EVIDENCE CODES\n",
    "# ====================================================\n",
    "# HARDWARE: High RAM (32GB+) & Disk Space (20GB+)\n",
    "# ====================================================\n",
    "\n",
    "# We acquire external UniProt annotations to distinguish between \n",
    "# Experimental (Kaggle) and Electronic (No-Kaggle) labels.\n",
    "# This is crucial for the \"Rank 1\" strategy to boost recall.\n",
    "\n",
    "# Toggle to enable this heavy step\n",
    "PROCESS_EXTERNAL = False \n",
    "\n",
    "if PROCESS_EXTERNAL:\n",
    "    import requests\n",
    "    import gzip\n",
    "    import shutil\n",
    "    \n",
    "    EXT_DIR = ARTEFACTS_DIR / 'external'\n",
    "    EXT_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 1. Download UniProt GOA (Example URL - Verify version!)\n",
    "    # This file is ~8GB compressed, ~80GB uncompressed.\n",
    "    URL_GOA = \"http://ftp.ebi.ac.uk/pub/databases/GO/goa/old/UNIPROT/goa_uniprot_all.gaf.216.gz\"\n",
    "    gaf_path = EXT_DIR / 'goa_uniprot_all.gaf.gz'\n",
    "    \n",
    "    if not gaf_path.exists():\n",
    "        print(f\"Downloading External Data from {URL_GOA}...\")\n",
    "        try:\n",
    "            with requests.get(URL_GOA, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(gaf_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "            print(\"Download complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Download failed: {e}\")\n",
    "            # Cleanup partial file\n",
    "            if gaf_path.exists(): gaf_path.unlink()\n",
    "    \n",
    "    # 2. Parse & Split Evidence Codes\n",
    "    # We need to parse the GAF file and separate annotations based on Evidence Code.\n",
    "    # Experimental: EXP, IDA, IPI, IMP, IGI, IEP\n",
    "    # Electronic: IEA\n",
    "    \n",
    "    EXP_CODES = {'EXP', 'IDA', 'IPI', 'IMP', 'IGI', 'IEP'}\n",
    "    \n",
    "    print(\"Parsing GAF file (this will take a while)...\")\n",
    "    # Simplified parser for demonstration\n",
    "    # In production, use a specialized parser or awk/sed for speed\n",
    "    \n",
    "    # Output files\n",
    "    path_no_kaggle = ARTEFACTS_DIR / 'parsed' / 'prop_train_no_kaggle.tsv'\n",
    "    \n",
    "    if not path_no_kaggle.exists():\n",
    "        with gzip.open(gaf_path, 'rt') as f_in, open(path_no_kaggle, 'w') as f_out:\n",
    "            f_out.write(\"EntryID\\tterm\\n\")\n",
    "            for line in f_in:\n",
    "                if line.startswith('!'): continue\n",
    "                parts = line.split('\\t')\n",
    "                \n",
    "                # GAF 2.1 Format:\n",
    "                # DB, DB_Object_ID, DB_Object_Symbol, Qualifier, GO_ID, DB:Reference, Evidence_Code, ...\n",
    "                # Index 1: ID, Index 4: GO_ID, Index 6: Evidence\n",
    "                \n",
    "                obj_id = parts[1]\n",
    "                go_id = parts[4]\n",
    "                evidence = parts[6]\n",
    "                \n",
    "                # We want \"No-Kaggle\" (Electronic) labels for features\n",
    "                if evidence not in EXP_CODES:\n",
    "                    f_out.write(f\"{obj_id}\\t{go_id}\\n\")\n",
    "                    \n",
    "        print(f\"Saved No-Kaggle features to {path_no_kaggle}\")\n",
    "    else:\n",
    "        print(\"No-Kaggle features already parsed.\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping External Data (PROCESS_EXTERNAL=False).\")\n",
    "    print(\"To implement Rank 1 fully, set PROCESS_EXTERNAL=True and ensure sufficient disk space.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e395534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading sequences for embedding...\n",
      "Loading T5 Model...\n",
      "Loading T5 Model...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 144\u001b[39m\n\u001b[32m    141\u001b[39m     test_df = pd.read_feather(ARTEFACTS_DIR / \u001b[33m'\u001b[39m\u001b[33mparsed\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mtest_seq.feather\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# 1. Run T5\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m tokenizer, model = \u001b[43mget_t5_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating Train Embeddings T5 (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    146\u001b[39m train_emb = generate_embeddings_t5(model, tokenizer, train_df[\u001b[33m'\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m'\u001b[39m].tolist())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mget_t5_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading T5 Model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Added legacy=True to silence warning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m tokenizer = \u001b[43mT5Tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mRostlab/prot_t5_xl_half_uniref50-enc\u001b[39m\u001b[33m\"\u001b[39m, do_lower_case=\u001b[38;5;28;01mFalse\u001b[39;00m, legacy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     35\u001b[39m model = T5EncoderModel.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mRostlab/prot_t5_xl_half_uniref50-enc\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m     36\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olale\\miniconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2157\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   2155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m2157\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Olale\\miniconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2143\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   2140\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   2142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m2143\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Check out the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# 3. PHASE 1: EMBEDDINGS GENERATION (T5 & ESM2)\n",
    "# ==========================================\n",
    "# HARDWARE: GPU (P100 preferred, or T4x2)\n",
    "# ==========================================\n",
    "\n",
    "# We generate embeddings using T5 (Sequence) and ESM2 (Structure/Evolution).\n",
    "# NOTE: This requires a GPU. Set COMPUTE_EMBEDDINGS = True to run.\n",
    "\n",
    "COMPUTE_EMBEDDINGS = True  # <--- ENABLED FOR RUNNING\n",
    "\n",
    "if COMPUTE_EMBEDDINGS:\n",
    "    import os\n",
    "    # Optimize CUDA memory allocation\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "    # Fix Protobuf 'GetPrototype' error\n",
    "    os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "    \n",
    "    import torch\n",
    "    from transformers import T5Tokenizer, T5EncoderModel, EsmTokenizer, EsmModel\n",
    "    from tqdm.auto import tqdm\n",
    "    import gc\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # T5 Embeddings\n",
    "    # ------------------------------------------\n",
    "    def get_t5_model():\n",
    "        print(\"Loading T5 Model...\")\n",
    "        # Added legacy=True to silence warning\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\", do_lower_case=False, legacy=True)\n",
    "        model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\").to(device)\n",
    "        model.eval()\n",
    "        return tokenizer, model\n",
    "\n",
    "    # SMART BATCHING: Sort by length to minimize padding\n",
    "    def generate_embeddings_t5(model, tokenizer, sequences, batch_size=4, max_len=1024):\n",
    "        # 1. Sort sequences by length (Descending to fail fast on OOM)\n",
    "        seq_lens = [len(s) for s in sequences]\n",
    "        sort_idx = np.argsort(seq_lens)[::-1]\n",
    "        sorted_seqs = [sequences[i] for i in sort_idx]\n",
    "        \n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(sorted_seqs), batch_size), desc=\"Embedding T5 (Smart Batch)\"):\n",
    "            batch_seqs = sorted_seqs[i : i + batch_size]\n",
    "            \n",
    "            # Clean sequences\n",
    "            batch_seqs = [seq.replace('U','X').replace('Z','X').replace('O','X').replace('B','X') for seq in batch_seqs]\n",
    "            batch_seqs = [\" \".join(list(seq)) for seq in batch_seqs]\n",
    "\n",
    "            ids = tokenizer.batch_encode_plus(\n",
    "                batch_seqs, add_special_tokens=True, padding=\"longest\", \n",
    "                truncation=True, max_length=max_len, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    embedding_repr = model(input_ids=ids['input_ids'], attention_mask=ids['attention_mask'])\n",
    "            \n",
    "            emb = embedding_repr.last_hidden_state.float().detach().cpu().numpy()\n",
    "            mask = ids['attention_mask'].cpu().numpy()\n",
    "            \n",
    "            for j in range(len(batch_seqs)):\n",
    "                seq_len = mask[j].sum()\n",
    "                valid_emb = emb[j, :seq_len]\n",
    "                mean_emb = valid_emb.mean(axis=0)\n",
    "                embeddings_list.append(mean_emb)\n",
    "                \n",
    "            del ids, embedding_repr, emb, mask\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # 2. Restore original order\n",
    "        sorted_embeddings = np.vstack(embeddings_list)\n",
    "        original_order_embeddings = np.zeros_like(sorted_embeddings)\n",
    "        original_order_embeddings[sort_idx] = sorted_embeddings\n",
    "        \n",
    "        return original_order_embeddings\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # ESM2 Embeddings\n",
    "    # ------------------------------------------\n",
    "    def get_esm2_model():\n",
    "        print(\"Loading ESM2 Model...\")\n",
    "        # facebook/esm2_t33_650M_UR50D is a good balance\n",
    "        model_name = \"facebook/esm2_t33_650M_UR50D\" \n",
    "        tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "        model = EsmModel.from_pretrained(model_name).to(device)\n",
    "        model.eval()\n",
    "        return tokenizer, model\n",
    "\n",
    "    # Increased Batch Size to 16 for ESM2 (Smaller model) + Smart Batching\n",
    "    def generate_embeddings_esm2(model, tokenizer, sequences, batch_size=16, max_len=1024):\n",
    "        # 1. Sort sequences\n",
    "        seq_lens = [len(s) for s in sequences]\n",
    "        sort_idx = np.argsort(seq_lens)[::-1]\n",
    "        sorted_seqs = [sequences[i] for i in sort_idx]\n",
    "        \n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(sorted_seqs), batch_size), desc=\"Embedding ESM2 (Smart Batch)\"):\n",
    "            batch_seqs = sorted_seqs[i : i + batch_size]\n",
    "            \n",
    "            ids = tokenizer.batch_encode_plus(\n",
    "                batch_seqs, add_special_tokens=True, padding=\"longest\", \n",
    "                truncation=True, max_length=max_len, return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    output = model(input_ids=ids['input_ids'], attention_mask=ids['attention_mask'])\n",
    "            \n",
    "            emb = output.last_hidden_state.float().detach().cpu().numpy()\n",
    "            mask = ids['attention_mask'].cpu().numpy()\n",
    "            \n",
    "            for j in range(len(batch_seqs)):\n",
    "                seq_len = mask[j].sum()\n",
    "                valid_emb = emb[j, :seq_len]\n",
    "                mean_emb = valid_emb.mean(axis=0)\n",
    "                embeddings_list.append(mean_emb)\n",
    "                \n",
    "            del ids, output, emb, mask\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        # 2. Restore order\n",
    "        sorted_embeddings = np.vstack(embeddings_list)\n",
    "        original_order_embeddings = np.zeros_like(sorted_embeddings)\n",
    "        original_order_embeddings[sort_idx] = sorted_embeddings\n",
    "        \n",
    "        return original_order_embeddings\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Execution\n",
    "    # ------------------------------------------\n",
    "    print(\"Loading sequences for embedding...\")\n",
    "    train_df = pd.read_feather(ARTEFACTS_DIR / 'parsed' / 'train_seq.feather')\n",
    "    if PATH_TEST_FASTA.exists():\n",
    "        test_df = pd.read_feather(ARTEFACTS_DIR / 'parsed' / 'test_seq.feather')\n",
    "    \n",
    "    # 1. Run T5\n",
    "    tokenizer, model = get_t5_model()\n",
    "    print(f\"Generating Train Embeddings T5 ({len(train_df)})...\")\n",
    "    train_emb = generate_embeddings_t5(model, tokenizer, train_df['sequence'].tolist())\n",
    "    np.save(ARTEFACTS_DIR / 'features' / 'train_embeds_t5.npy', train_emb)\n",
    "    del train_emb\n",
    "    gc.collect()\n",
    "\n",
    "    if PATH_TEST_FASTA.exists():\n",
    "        print(f\"Generating Test Embeddings T5 ({len(test_df)})...\")\n",
    "        test_emb = generate_embeddings_t5(model, tokenizer, test_df['sequence'].tolist())\n",
    "        np.save(ARTEFACTS_DIR / 'features' / 'test_embeds_t5.npy', test_emb)\n",
    "        del test_emb\n",
    "    \n",
    "    del model, tokenizer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 2. Run ESM2\n",
    "    tokenizer, model = get_esm2_model()\n",
    "    print(f\"Generating Train Embeddings ESM2 ({len(train_df)})...\")\n",
    "    train_emb = generate_embeddings_esm2(model, tokenizer, train_df['sequence'].tolist())\n",
    "    np.save(ARTEFACTS_DIR / 'features' / 'train_embeds_esm2.npy', train_emb)\n",
    "    del train_emb\n",
    "    gc.collect()\n",
    "\n",
    "    if PATH_TEST_FASTA.exists():\n",
    "        print(f\"Generating Test Embeddings ESM2 ({len(test_df)})...\")\n",
    "        test_emb = generate_embeddings_esm2(model, tokenizer, test_df['sequence'].tolist())\n",
    "        np.save(ARTEFACTS_DIR / 'features' / 'test_embeds_esm2.npy', test_emb)\n",
    "        del test_emb\n",
    "\n",
    "    del model, tokenizer, train_df\n",
    "    if PATH_TEST_FASTA.exists(): del test_df\n",
    "    gc.collect()\n",
    "    print(\"All embeddings generated.\")\n",
    "else:\n",
    "    print(\"Skipping embedding generation (COMPUTE_EMBEDDINGS=False).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. PHASE 2: LEVEL-1 MODELS (DIVERSE ENSEMBLE)\n",
    "# =============================================\n",
    "# HARDWARE: GPU (32GB+ recommended for full run)\n",
    "# =============================================\n",
    "\n",
    "# We train a diverse set of models:\n",
    "# 1. Logistic Regression (Baseline)\n",
    "# 2. Py-Boost (GBDT) - Requires 'py-boost' package\n",
    "# 3. DNN Ensemble (Deep Learning)\n",
    "\n",
    "TRAIN_LEVEL1 = True\n",
    "\n",
    "if TRAIN_LEVEL1:\n",
    "    import joblib\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import f1_score\n",
    "    import os\n",
    "    \n",
    "    # Load Data\n",
    "    print(\"Loading Embeddings & Targets...\")\n",
    "    X = np.load(ARTEFACTS_DIR / 'features' / 'train_embeds_t5.npy')\n",
    "    train_terms = pd.read_parquet(ARTEFACTS_DIR / 'parsed' / 'train_terms.parquet')\n",
    "    train_ids = pd.read_feather(ARTEFACTS_DIR / 'parsed' / 'train_seq.feather')['id']\n",
    "    \n",
    "    # Target Matrix Construction (Top K Terms)\n",
    "    TOP_K = 1500 # Increased for better coverage\n",
    "    top_terms = train_terms['term'].value_counts().head(TOP_K).index.tolist()\n",
    "    \n",
    "    train_terms_top = train_terms[train_terms['term'].isin(top_terms)]\n",
    "    Y_df = train_terms_top.pivot_table(index='EntryID', columns='term', aggfunc='size', fill_value=0)\n",
    "    Y_df = Y_df.reindex(train_ids, fill_value=0)\n",
    "    Y = Y_df.values\n",
    "    \n",
    "    print(f\"Data: X={X.shape}, Y={Y.shape}\")\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # A. Logistic Regression (Baseline)\n",
    "    # ------------------------------------------\n",
    "    print(\"\\n--- Training Logistic Regression ---\")\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    \n",
    "    clf_logreg = OneVsRestClassifier(LogisticRegression(max_iter=500, solver='sag', n_jobs=1, C=1.0))\n",
    "    clf_logreg.n_jobs = -1\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    oof_preds_logreg = np.zeros(Y.shape)\n",
    "    \n",
    "    for fold, (idx_tr, idx_val) in enumerate(kf.split(X)):\n",
    "        print(f\"LogReg Fold {fold+1}/5\")\n",
    "        X_tr, X_val = X[idx_tr], X[idx_val]\n",
    "        Y_tr, Y_val = Y[idx_tr], Y[idx_val]\n",
    "        \n",
    "        clf_logreg.fit(X_tr, Y_tr)\n",
    "        \n",
    "        # Predict\n",
    "        val_probs = clf_logreg.predict_proba(X_val)\n",
    "        oof_preds_logreg[idx_val] = val_probs\n",
    "        \n",
    "        # Metric Calculation\n",
    "        val_preds = (val_probs > 0.3).astype(int) # Threshold 0.3\n",
    "        f1 = f1_score(Y_val, val_preds, average='micro')\n",
    "        print(f\"  >> Fold {fold+1} F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        # Save Model\n",
    "        joblib.dump(clf_logreg, ARTEFACTS_DIR / 'features' / f'level1_logreg_fold{fold}.pkl')\n",
    "            \n",
    "    np.save(ARTEFACTS_DIR / 'features' / 'oof_logreg.npy', oof_preds_logreg)\n",
    "    print(\"LogReg OOF saved.\")\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # B. Py-Boost (GBDT)\n",
    "    # ------------------------------------------\n",
    "    try:\n",
    "        from py_boost import GradientBoosting\n",
    "        HAS_PYBOOST = True\n",
    "    except ImportError:\n",
    "        print(\"\\n[WARNING] Py-Boost not installed. Skipping GBDT.\")\n",
    "        HAS_PYBOOST = False\n",
    "        \n",
    "    if HAS_PYBOOST:\n",
    "        print(\"\\n--- Training Py-Boost GBDT ---\")\n",
    "        oof_preds_gbdt = np.zeros(Y.shape)\n",
    "        \n",
    "        for fold, (idx_tr, idx_val) in enumerate(kf.split(X)):\n",
    "            print(f\"GBDT Fold {fold+1}/5\")\n",
    "            X_tr, X_val = X[idx_tr], X[idx_val]\n",
    "            Y_tr, Y_val = Y[idx_tr], Y[idx_val]\n",
    "            \n",
    "            model = GradientBoosting(\n",
    "                loss='bce', \n",
    "                ntrees=1000, \n",
    "                lr=0.05, \n",
    "                max_depth=6,\n",
    "                verbose=100,\n",
    "                es=50\n",
    "            )\n",
    "            \n",
    "            model.fit(X_tr, Y_tr, eval_sets=[{'X': X_val, 'y': Y_val}])\n",
    "            val_probs = model.predict(X_val)\n",
    "            oof_preds_gbdt[idx_val] = val_probs\n",
    "            \n",
    "            # Metric Calculation\n",
    "            val_preds = (val_probs > 0.3).astype(int)\n",
    "            f1 = f1_score(Y_val, val_preds, average='micro')\n",
    "            print(f\"  >> Fold {fold+1} F1 Score: {f1:.4f}\")\n",
    "            \n",
    "            # Save Model\n",
    "            model.save(str(ARTEFACTS_DIR / 'features' / f'level1_gbdt_fold{fold}.json'))\n",
    "            \n",
    "        np.save(ARTEFACTS_DIR / 'features' / 'oof_gbdt.npy', oof_preds_gbdt)\n",
    "        print(\"GBDT OOF saved.\")\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # C. DNN Ensemble (PyTorch)\n",
    "    # ------------------------------------------\n",
    "    print(\"\\n--- Training DNN Ensemble ---\")\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    \n",
    "    class SimpleDNN(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(input_dim, 2048),\n",
    "                nn.BatchNorm1d(2048),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(1024, output_dim),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "            \n",
    "    oof_preds_dnn = np.zeros(Y.shape)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for fold, (idx_tr, idx_val) in enumerate(kf.split(X)):\n",
    "        print(f\"DNN Fold {fold+1}/5\")\n",
    "        X_tr = torch.tensor(X[idx_tr], dtype=torch.float32).to(device)\n",
    "        Y_tr = torch.tensor(Y[idx_tr], dtype=torch.float32).to(device)\n",
    "        X_val_t = torch.tensor(X[idx_val], dtype=torch.float32).to(device)\n",
    "        \n",
    "        model = SimpleDNN(X.shape[1], Y.shape[1]).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        batch_size = 256\n",
    "        n_samples = X_tr.shape[0]\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(10):\n",
    "            perm = torch.randperm(n_samples)\n",
    "            for i in range(0, n_samples, batch_size):\n",
    "                idx = perm[i:i+batch_size]\n",
    "                optimizer.zero_grad()\n",
    "                out = model(X_tr[idx])\n",
    "                loss = criterion(out, Y_tr[idx])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_probs = model(X_val_t).cpu().numpy()\n",
    "            oof_preds_dnn[idx_val] = val_probs\n",
    "            \n",
    "        # Metric Calculation\n",
    "        val_preds = (val_probs > 0.3).astype(int)\n",
    "        f1 = f1_score(Y[idx_val], val_preds, average='micro')\n",
    "        print(f\"  >> Fold {fold+1} F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        # Save Model\n",
    "        torch.save(model.state_dict(), ARTEFACTS_DIR / 'features' / f'level1_dnn_fold{fold}.pth')\n",
    "            \n",
    "    np.save(ARTEFACTS_DIR / 'features' / 'oof_dnn.npy', oof_preds_dnn)\n",
    "    print(\"DNN OOF saved.\")\n",
    "    \n",
    "    print(\"Phase 2 Complete. OOF predictions generated.\")\n",
    "else:\n",
    "    print(\"Skipping Phase 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. PHASE 3: HIERARCHY-AWARE STACKING (GCN)\n",
    "# ==========================================\n",
    "# We use a Graph Convolutional Network (GCN) to learn the GO hierarchy structure\n",
    "# and refine the Level 1 predictions.\n",
    "\n",
    "TRAIN_STACKER = True\n",
    "\n",
    "if TRAIN_STACKER:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch_geometric.nn import GCNConv\n",
    "    from torch_geometric.data import Data\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    print(\"Loading OOF Predictions for Stacking...\")\n",
    "    # Load OOFs\n",
    "    oof_logreg = np.load(ARTEFACTS_DIR / 'features' / 'oof_logreg.npy')\n",
    "    # Check if GBDT/DNN exist, else use zeros (robustness)\n",
    "    try:\n",
    "        oof_gbdt = np.load(ARTEFACTS_DIR / 'features' / 'oof_gbdt.npy')\n",
    "    except:\n",
    "        oof_gbdt = np.zeros_like(oof_logreg)\n",
    "        \n",
    "    try:\n",
    "        oof_dnn = np.load(ARTEFACTS_DIR / 'features' / 'oof_dnn.npy')\n",
    "    except:\n",
    "        oof_dnn = np.zeros_like(oof_logreg)\n",
    "\n",
    "    # Stack features: (N_samples, N_terms, 3_models) -> (N_samples, N_terms * 3)\n",
    "    # Actually, GCN usually takes node features. \n",
    "    # Simplified Stacker: MLP on concatenated probs + Graph regularization\n",
    "    # Rank 1 Approach: GCN where nodes are GO terms.\n",
    "    # Input to GCN: Features for each term.\n",
    "    # But here we have predictions FOR each term.\n",
    "    # Let's implement a simplified \"Correction\" GCN.\n",
    "    # Node features = [LogReg_score, GBDT_score, DNN_score] for that term.\n",
    "    \n",
    "    print(\"Constructing Graph Data...\")\n",
    "    # We need the GO graph structure (edges)\n",
    "    # For this demo, we'll assume a random edge index if ontology not parsed, \n",
    "    # but ideally we load 'go-basic.obo'.\n",
    "    # Placeholder: Identity edges (self-loops) + random for demo\n",
    "    num_terms = oof_logreg.shape[1]\n",
    "    edge_index = torch.tensor([[i, i] for i in range(num_terms)], dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Prepare Input Tensor: Shape (Batch, Terms, Models)\n",
    "    # This is too big for standard GCN on full graph per sample.\n",
    "    # Rank 1 trick: Train one GCN per Ontology, or batch terms.\n",
    "    # Here we will use a simple MLP Stacker that learns term correlations via a dense layer\n",
    "    # instead of explicit GCN to save memory/complexity for this notebook.\n",
    "    \n",
    "    print(\"Training Stacker (MLP/GCN Simplified)...\")\n",
    "    \n",
    "    X_stack = np.hstack([oof_logreg, oof_gbdt, oof_dnn]) # Concatenate features\n",
    "    Y_stack = Y # Targets\n",
    "    \n",
    "    X_stack_t = torch.tensor(X_stack, dtype=torch.float32).to(device)\n",
    "    Y_stack_t = torch.tensor(Y_stack, dtype=torch.float32).to(device)\n",
    "    \n",
    "    class Stacker(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(input_dim, 2048),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(2048, output_dim),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "    stacker = Stacker(X_stack.shape[1], Y_stack.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(stacker.parameters(), lr=1e-3)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    stacker.train()\n",
    "    for epoch in range(20):\n",
    "        optimizer.zero_grad()\n",
    "        out = stacker(X_stack_t)\n",
    "        loss = criterion(out, Y_stack_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            # Calculate F1\n",
    "            with torch.no_grad():\n",
    "                preds = (out > 0.3).float()\n",
    "                # Calculate F1 on a subset to save time/memory\n",
    "                f1 = f1_score(Y_stack_t.cpu().numpy()[:1000], preds.cpu().numpy()[:1000], average='micro')\n",
    "            print(f\"Epoch {epoch}: Loss {loss.item():.4f}, Approx F1 {f1:.4f}\")\n",
    "            \n",
    "    # Save Stacker\n",
    "    torch.save(stacker.state_dict(), ARTEFACTS_DIR / 'features' / 'final_stacker.pth')\n",
    "    print(\"Stacker saved.\")\n",
    "    \n",
    "    # Final Evaluation\n",
    "    stacker.eval()\n",
    "    with torch.no_grad():\n",
    "        final_preds = stacker(X_stack_t).cpu().numpy()\n",
    "        final_f1 = f1_score(Y_stack, (final_preds > 0.3).astype(int), average='micro')\n",
    "    print(f\"Final Stacker F1 Score: {final_f1:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Phase 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f451671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. PHASE 3: HIERARCHY-AWARE STACKING (GCN)\n",
    "# ==========================================\n",
    "# HARDWARE: GPU (High VRAM recommended)\n",
    "# ==========================================\n",
    "\n",
    "# We train Graph Convolutional Networks (GCNs) to leverage the GO hierarchy.\n",
    "# INPUT: OOF Predictions from Phase 2 (LogReg, GBDT, DNN)\n",
    "# OUTPUT: Refined probabilities\n",
    "\n",
    "TRAIN_GCN = True\n",
    "\n",
    "if TRAIN_GCN:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    \n",
    "    # 1. Load OOF Predictions (Features for GCN)\n",
    "    print(\"Loading OOF Predictions...\")\n",
    "    features_list = []\n",
    "    \n",
    "    # Load available OOFs\n",
    "    if (ARTEFACTS_DIR / 'features' / 'oof_logreg.npy').exists():\n",
    "        features_list.append(np.load(ARTEFACTS_DIR / 'features' / 'oof_logreg.npy'))\n",
    "    if (ARTEFACTS_DIR / 'features' / 'oof_gbdt.npy').exists():\n",
    "        features_list.append(np.load(ARTEFACTS_DIR / 'features' / 'oof_gbdt.npy'))\n",
    "    if (ARTEFACTS_DIR / 'features' / 'oof_dnn.npy').exists():\n",
    "        features_list.append(np.load(ARTEFACTS_DIR / 'features' / 'oof_dnn.npy'))\n",
    "        \n",
    "    if not features_list:\n",
    "        raise FileNotFoundError(\"No OOF predictions found! Run Phase 2.\")\n",
    "        \n",
    "    # Concatenate OOFs to form GCN Input\n",
    "    # Shape: (N_samples, N_models * N_terms) -> This is huge.\n",
    "    # Rank 1 Strategy: Use OOFs as features.\n",
    "    # Simplified: Average them or use just one for demo if memory is tight.\n",
    "    # Let's use the average for stability and memory efficiency in this demo.\n",
    "    X_stack = np.mean(features_list, axis=0)\n",
    "    print(f\"Stacking Input Shape: {X_stack.shape}\")\n",
    "    \n",
    "    # Load Targets & Graph\n",
    "    train_terms = pd.read_parquet(ARTEFACTS_DIR / 'parsed' / 'train_terms.parquet')\n",
    "    train_ids = pd.read_feather(ARTEFACTS_DIR / 'parsed' / 'train_seq.feather')['id']\n",
    "    \n",
    "    # Re-create Y (same as Phase 2)\n",
    "    # Note: In a real run, ensure Y matches X_stack alignment\n",
    "    # Here we assume X_stack is aligned with train_ids (which it is, via KFold)\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # GCN Model & Training (Same as before, but input is Probabilities)\n",
    "    # ------------------------------------------\n",
    "    # ... (GCN Code reused from previous version, but input_dim matches X_stack)\n",
    "    \n",
    "    # Define GCN Utils\n",
    "    def build_adjacency(terms_list, parents_dict):\n",
    "        term_to_idx = {t: i for i, t in enumerate(terms_list)}\n",
    "        n_terms = len(terms_list)\n",
    "        src, dst = [], []\n",
    "        for child in terms_list:\n",
    "            if child in parents_dict:\n",
    "                child_idx = term_to_idx[child]\n",
    "                for parent in parents_dict[child]:\n",
    "                    if parent in term_to_idx:\n",
    "                        parent_idx = term_to_idx[parent]\n",
    "                        src.append(child_idx); dst.append(parent_idx)\n",
    "                        src.append(parent_idx); dst.append(child_idx)\n",
    "        src.extend(range(n_terms))\n",
    "        dst.extend(range(n_terms))\n",
    "        indices = torch.tensor([src, dst], dtype=torch.long)\n",
    "        values = torch.ones(len(src), dtype=torch.float)\n",
    "        return torch.sparse_coo_tensor(indices, values, (n_terms, n_terms)).to(device)\n",
    "\n",
    "    class SimpleGCN(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, adj_matrix):\n",
    "            super().__init__()\n",
    "            self.adj = adj_matrix\n",
    "            # Input is (Batch, N_terms). We project to Hidden, then GraphConv.\n",
    "            self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "            self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = torch.sparse.mm(self.adj, x.t()).t()\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "    # Training Loop\n",
    "    ontologies = {'BP': 'biological_process', 'MF': 'molecular_function', 'CC': 'cellular_component'}\n",
    "    \n",
    "    # We need to map the 1500 terms in X_stack to the specific ontology terms\n",
    "    # This mapping is tricky if X_stack is a flat 1500 vector.\n",
    "    # For simplicity: We train the GCN to refine the *same* 1500 terms.\n",
    "    # So Input Dim = 1500, Output Dim = 1500 (or subset).\n",
    "    \n",
    "    # Let's train one global GCN for all 1500 terms for simplicity in this fix.\n",
    "    # In full Rank 1, they split by ontology.\n",
    "    \n",
    "    print(\"\\n=== Training Global GCN Stacker ===\")\n",
    "    \n",
    "    # Build Graph for ALL 1500 terms\n",
    "    # We need the list of 1500 terms used in Phase 2\n",
    "    TOP_K = 1500\n",
    "    top_terms = train_terms['term'].value_counts().head(TOP_K).index.tolist()\n",
    "    \n",
    "    adj = build_adjacency(top_terms, go_parents)\n",
    "    \n",
    "    # Prepare Data\n",
    "    X_tensor = torch.tensor(X_stack, dtype=torch.float).to(device)\n",
    "    \n",
    "    # Targets\n",
    "    train_terms_top = train_terms[train_terms['term'].isin(top_terms)]\n",
    "    Y_df = train_terms_top.pivot_table(index='EntryID', columns='term', aggfunc='size', fill_value=0)\n",
    "    Y_df = Y_df.reindex(train_ids, fill_value=0)\n",
    "    Y_tensor = torch.tensor(Y_df.values, dtype=torch.float).to(device)\n",
    "    \n",
    "    model = SimpleGCN(input_dim=TOP_K, hidden_dim=2048, output_dim=TOP_K, adj_matrix=adj).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    BATCH_SIZE = 64\n",
    "    n_samples = X_tensor.shape[0]\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        total_loss = 0\n",
    "        perm = torch.randperm(n_samples)\n",
    "        for i in range(0, n_samples, BATCH_SIZE):\n",
    "            idx = perm[i:i+BATCH_SIZE]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_tensor[idx])\n",
    "            loss = criterion(outputs, Y_tensor[idx])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / (n_samples/BATCH_SIZE):.4f}\")\n",
    "        \n",
    "    torch.save(model.state_dict(), ARTEFACTS_DIR / 'features' / 'gcn_stacker.pth')\n",
    "    print(\"GCN Stacker saved.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping GCN Training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. PHASE 4: POST-PROCESSING & SUBMISSION\n",
    "# ========================================\n",
    "# HARDWARE: CPU / GPU\n",
    "# ========================================\n",
    "\n",
    "# This phase applies the \"Strict Post-Processing\" rules (Max/Min Propagation)\n",
    "# and generates the final submission file.\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "# Check if submission already exists\n",
    "if (ARTEFACTS_DIR / 'submission.tsv').exists():\n",
    "    print(\"submission.tsv already exists. Skipping Phase 4.\")\n",
    "else:\n",
    "    print(\"Starting Phase 4: Inference & Post-processing...\")\n",
    "    \n",
    "    # Setup Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 1. Load Test Data\n",
    "    print(\"Loading Test Embeddings...\")\n",
    "    if not (ARTEFACTS_DIR / 'features' / 'test_embeds_t5.npy').exists():\n",
    "        raise FileNotFoundError(\"Test embeddings not found! Run Phase 1.\")\n",
    "        \n",
    "    X_test = np.load(ARTEFACTS_DIR / 'features' / 'test_embeds_t5.npy')\n",
    "    test_ids = pd.read_feather(ARTEFACTS_DIR / 'parsed' / 'test_seq.feather')['id']\n",
    "    \n",
    "    # Ensure go_parents is available (from Cell 2)\n",
    "    if 'go_parents' not in locals():\n",
    "        print(\"Reloading GO Graph...\")\n",
    "        import obonet\n",
    "        graph = obonet.read_obo(PATH_GO_OBO)\n",
    "        go_parents = {node: set(values) for node, values in graph.adj.items()}\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Re-define GCN Utils (for standalone execution)\n",
    "    # ------------------------------------------\n",
    "    def build_adjacency(terms_list, parents_dict):\n",
    "        term_to_idx = {t: i for i, t in enumerate(terms_list)}\n",
    "        n_terms = len(terms_list)\n",
    "        src, dst = [], []\n",
    "        for child in terms_list:\n",
    "            if child in parents_dict:\n",
    "                child_idx = term_to_idx[child]\n",
    "                for parent in parents_dict[child]:\n",
    "                    if parent in term_to_idx:\n",
    "                        parent_idx = term_to_idx[parent]\n",
    "                        src.append(child_idx); dst.append(parent_idx)\n",
    "                        src.append(parent_idx); dst.append(child_idx)\n",
    "        src.extend(range(n_terms))\n",
    "        dst.extend(range(n_terms))\n",
    "        indices = torch.tensor([src, dst], dtype=torch.long)\n",
    "        values = torch.ones(len(src), dtype=torch.float)\n",
    "        return torch.sparse_coo_tensor(indices, values, (n_terms, n_terms)).to(device)\n",
    "\n",
    "    class SimpleGCN(torch.nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim, adj_matrix):\n",
    "            super().__init__()\n",
    "            self.adj = adj_matrix\n",
    "            self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "            self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = torch.sparse.mm(self.adj, x.t()).t()\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Inference & Propagation Loop\n",
    "    # ------------------------------------------\n",
    "    ontologies = {'BP': 'biological_process', 'MF': 'molecular_function', 'CC': 'cellular_component'}\n",
    "    final_preds = []\n",
    "\n",
    "    for ont_code, ont_ns in ontologies.items():\n",
    "        print(f\"\\nProcessing {ont_code}...\")\n",
    "        \n",
    "        # Re-select Terms (Must match training logic exactly)\n",
    "        train_terms = pd.read_parquet(ARTEFACTS_DIR / 'parsed' / 'train_terms.parquet')\n",
    "        ont_terms_all = train_terms[train_terms['aspect'] == ont_ns]['term'].value_counts()\n",
    "        ont_terms_list = ont_terms_all.head(500).index.tolist()\n",
    "        \n",
    "        # Build Graph & Model\n",
    "        adj = build_adjacency(ont_terms_list, go_parents)\n",
    "        model = SimpleGCN(input_dim=X_test.shape[1], hidden_dim=1024, output_dim=len(ont_terms_list), adj_matrix=adj).to(device)\n",
    "        \n",
    "        model_path = ARTEFACTS_DIR / 'features' / f'gcn_{ont_code}.pth'\n",
    "        if not model_path.exists():\n",
    "            print(f\"Warning: Model {model_path} not found. Skipping {ont_code}.\")\n",
    "            continue\n",
    "            \n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        \n",
    "        # Inference\n",
    "        print(\"Running Inference...\")\n",
    "        X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
    "        preds = []\n",
    "        BATCH_SIZE = 1024\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_tensor), BATCH_SIZE):\n",
    "                batch_out = model(X_tensor[i:i+BATCH_SIZE])\n",
    "                preds.append(batch_out.cpu().numpy())\n",
    "        preds = np.vstack(preds)\n",
    "        \n",
    "        # ------------------------------------------\n",
    "        # Post-Processing (Max/Min Propagation)\n",
    "        # ------------------------------------------\n",
    "        print(\"Applying Hierarchy Rules...\")\n",
    "        df_pred = pd.DataFrame(preds, columns=ont_terms_list)\n",
    "        \n",
    "        # Map relationships within subset\n",
    "        term_to_parents = {}\n",
    "        term_to_children = {}\n",
    "        \n",
    "        for term in ont_terms_list:\n",
    "            parents = go_parents.get(term, set()).intersection(set(ont_terms_list))\n",
    "            if parents:\n",
    "                term_to_parents[term] = list(parents)\n",
    "                for p in parents:\n",
    "                    if p not in term_to_children: term_to_children[p] = []\n",
    "                    term_to_children[p].append(term)\n",
    "\n",
    "        # Max Propagation (Child -> Parent)\n",
    "        # \"If child is high, parent must be at least as high\"\n",
    "        for _ in range(2): # 2 passes for depth\n",
    "            for child, parents in term_to_parents.items():\n",
    "                child_scores = df_pred[child].values\n",
    "                for parent in parents:\n",
    "                    df_pred[parent] = np.maximum(df_pred[parent].values, child_scores)\n",
    "\n",
    "        # Min Propagation (Parent -> Child)\n",
    "        # \"If parent is low, child cannot be higher\"\n",
    "        for _ in range(2):\n",
    "            for parent, children in term_to_children.items():\n",
    "                parent_scores = df_pred[parent].values\n",
    "                for child in children:\n",
    "                    df_pred[child] = np.minimum(df_pred[child].values, parent_scores)\n",
    "        \n",
    "        # Format for Submission\n",
    "        df_pred['EntryID'] = test_ids.values\n",
    "        df_long = df_pred.melt(id_vars='EntryID', var_name='term', value_name='score')\n",
    "        # Filter low scores to save space (optional, keeping all for now or thresholding)\n",
    "        df_long = df_long[df_long['score'] > 0.001] \n",
    "        final_preds.append(df_long)\n",
    "        \n",
    "        # Cleanup\n",
    "        del model, adj, X_tensor, preds, df_pred, df_long\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Final Submission\n",
    "    # ------------------------------------------\n",
    "    if final_preds:\n",
    "        print(\"\\nGenerating final submission file...\")\n",
    "        submission = pd.concat(final_preds)\n",
    "        \n",
    "        # Sort and keep top 1500 per protein (Competition Rule)\n",
    "        # Note: This can be slow. For efficiency, we can do it per group or just save.\n",
    "        # Given the scale (500 terms * 3 ontologies = 1500 max), we might not need to filter heavily \n",
    "        # if we only predicted 1500 terms total.\n",
    "        \n",
    "        submission.to_csv(ARTEFACTS_DIR / 'submission.tsv', sep='\\t', index=False, header=False)\n",
    "        # Note: CAFA submission usually requires no header, or specific header. \n",
    "        # Sample submission has header: \"EntryID\tterm\tscore\" ? \n",
    "        # Let's check sample_submission.tsv\n",
    "        \n",
    "        print(f\"Done! Submission saved to {ARTEFACTS_DIR / 'submission.tsv'}\")\n",
    "    else:\n",
    "        print(\"No predictions generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf182ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. PHASE 5: FREE TEXT PREDICTION (OPTIONAL)\n",
    "# ==========================================\n",
    "# HARDWARE: CPU\n",
    "# ==========================================\n",
    "\n",
    "# This phase generates descriptive text for proteins, as required by the optional challenge.\n",
    "# We will generate a simple template-based description using the top predicted GO terms.\n",
    "\n",
    "if (ARTEFACTS_DIR / 'submission_with_text.tsv').exists():\n",
    "    print(\"submission_with_text.tsv already exists. Skipping Phase 5.\")\n",
    "elif not (ARTEFACTS_DIR / 'submission.tsv').exists():\n",
    "    print(\"submission.tsv not found. Please run Phase 4 first.\")\n",
    "else:\n",
    "    print(\"Starting Phase 5: Text Generation...\")\n",
    "    \n",
    "    # 1. Load Submission & GO Graph\n",
    "    print(\"Loading submission and GO data...\")\n",
    "    submission = pd.read_csv(ARTEFACTS_DIR / 'submission.tsv', sep='\\t', header=None, names=['EntryID', 'term', 'score'])\n",
    "    \n",
    "    if 'graph' not in locals():\n",
    "        import obonet\n",
    "        graph = obonet.read_obo(PATH_GO_OBO)\n",
    "    \n",
    "    # 2. Generate Text Descriptions\n",
    "    # Strategy: For each protein, take the top 3 predicted terms and form a sentence.\n",
    "    print(\"Generating descriptions...\")\n",
    "    \n",
    "    text_rows = []\n",
    "    \n",
    "    # Group by Protein ID\n",
    "    # (Processing a subset for demonstration speed, remove .head() for full run)\n",
    "    unique_ids = submission['EntryID'].unique()\n",
    "    \n",
    "    # Pre-fetch term names to avoid graph lookups in loop\n",
    "    term_names = {node: data.get('name', 'unknown function') for node, data in graph.nodes(data=True)}\n",
    "    \n",
    "    for protein_id in tqdm(unique_ids, desc=\"Generating Text\"):\n",
    "        # Get top terms for this protein\n",
    "        prot_preds = submission[submission['EntryID'] == protein_id]\n",
    "        top_terms = prot_preds.sort_values('score', ascending=False).head(3)\n",
    "        \n",
    "        if top_terms.empty:\n",
    "            description = f\"{protein_id} has no confident function predictions.\"\n",
    "            score = 0.0\n",
    "        else:\n",
    "            # Construct sentence\n",
    "            term_descs = []\n",
    "            for _, row in top_terms.iterrows():\n",
    "                term_id = row['term']\n",
    "                term_name = term_names.get(term_id, term_id)\n",
    "                term_descs.append(term_name)\n",
    "            \n",
    "            joined_terms = \", \".join(term_descs)\n",
    "            description = f\"{protein_id} is predicted to be involved in: {joined_terms}.\"\n",
    "            score = top_terms.iloc[0]['score'] # Use highest score as confidence\n",
    "            \n",
    "        # Format: EntryID, \"Text\", Score, Description\n",
    "        # Note: The sample submission format for text is: ID <tab> Text <tab> Score <tab> Description\n",
    "        # But we need to append this to the main submission file? \n",
    "        # Usually text predictions are a separate track or mixed in. \n",
    "        # Based on sample: A0A0C5B5G6 Text 0.123 Description...\n",
    "        \n",
    "        text_rows.append({\n",
    "            'EntryID': protein_id,\n",
    "            'term': 'Text',\n",
    "            'score': score,\n",
    "            'description': description\n",
    "        })\n",
    "        \n",
    "    # 3. Create Text DataFrame\n",
    "    df_text = pd.DataFrame(text_rows)\n",
    "    \n",
    "    # 4. Merge and Save\n",
    "    # The final file should contain both GO term predictions and Text predictions.\n",
    "    # However, the columns might differ. \n",
    "    # Standard rows: ID, Term, Score\n",
    "    # Text rows: ID, \"Text\", Score, Description\n",
    "    # We can save a separate text submission or append if the format allows 4 columns (unlikely for standard evaluators).\n",
    "    # Let's check the sample submission again.\n",
    "    # Sample: \n",
    "    # A0A0C5B5G6      GO:0000001      0.123\n",
    "    # A0A0C5B5G6      Text    0.123   Regulates insulin...\n",
    "    \n",
    "    # So it is a mixed file. We need to handle the 4th column.\n",
    "    # Standard rows have 3 columns. Text rows have 4.\n",
    "    # We will write this manually to ensure correct formatting.\n",
    "    \n",
    "    print(\"Saving combined submission...\")\n",
    "    \n",
    "    with open(ARTEFACTS_DIR / 'submission_with_text.tsv', 'w') as f:\n",
    "        # Write GO predictions (3 cols)\n",
    "        # We iterate the dataframe to write line by line or use to_csv and then append text\n",
    "        # Faster: Save GO preds to file, then append text rows\n",
    "        \n",
    "        # 1. Write GO Preds\n",
    "        submission.to_csv(f, sep='\\t', index=False, header=False)\n",
    "        \n",
    "        # 2. Write Text Preds\n",
    "        # ID \\t Text \\t Score \\t Description\n",
    "        for _, row in df_text.iterrows():\n",
    "            f.write(f\"{row['EntryID']}\\tText\\t{row['score']:.3f}\\t{row['description']}\\n\")\n",
    "            \n",
    "    print(f\"Done! Combined submission saved to {ARTEFACTS_DIR / 'submission_with_text.tsv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
