{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d091b52",
   "metadata": {},
   "source": [
    "# ESM-2 150M Fine-tuning (Enhanced Architecture)\n",
    "\n",
    "**Purpose:** Corrected pipeline with:\n",
    "- **Three separate heads** (MF, BP, CC) instead of single head\n",
    "- **Attention pooling** instead of mean pooling\n",
    "- **Layer freezing schedule** (freeze 90% for epoch 1, then unfreeze)\n",
    "- **Enhanced AsymmetricLoss** with label smoothing\n",
    "- **Per-aspect thresholds** (MF=0.40, BP=0.06, CC=0.30)\n",
    "\n",
    "**Expected improvement:** Better BP performance through dedicated head + lower threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2291107",
   "metadata": {},
   "source": [
    "## 1. Environment and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import AutoTokenizer, EsmModel, get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Device check\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"âœ… Imports successful\")\n",
    "print(f\"ðŸ–¥ï¸  Device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd85c5",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIRONMENT = 'local'\n",
    "\n",
    "# Handle running from notebooks/ or project root\n",
    "if Path.cwd().name == 'notebooks':\n",
    "    BASE_DIR = Path.cwd().parent\n",
    "else:\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    'model_name': 'facebook/esm2_t30_150M_UR50D',  # 150M parameters\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 2,\n",
    "    'gradient_accumulation': 16,  # Effective batch: 32\n",
    "    'learning_rate': 1e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'num_epochs': 3,\n",
    "    'warmup_ratio': 0.1,\n",
    "    'max_length': 448,\n",
    "    \n",
    "    # Model architecture\n",
    "    'dropout': 0.3,\n",
    "    'freeze_ratio': 0.9,  # Freeze 90% of layers in epoch 1\n",
    "    \n",
    "    # Asymmetric Loss\n",
    "    'gamma_neg': 4.0,\n",
    "    'gamma_pos': 1.0,\n",
    "    'clip': 0.05,\n",
    "    'label_smoothing': 0.01,\n",
    "    \n",
    "    # Per-aspect thresholds (from enhanced config)\n",
    "    'thresholds': {\n",
    "        'MF': 0.40,\n",
    "        'BP': 0.06,  # Lower for BP to capture more predictions\n",
    "        'CC': 0.30\n",
    "    },\n",
    "    \n",
    "    # Paths\n",
    "    'data_dir': BASE_DIR,\n",
    "    'output_dir': BASE_DIR / 'models' / 'esm_threehead',\n",
    "    'train_fasta': BASE_DIR / 'Train' / 'train_sequences.fasta',\n",
    "    'train_terms': BASE_DIR / 'Train' / 'train_terms.tsv',\n",
    "    'obo_path': BASE_DIR / 'Train' / 'go-basic.obo',\n",
    "    \n",
    "    # Reproducibility\n",
    "    'seed': 42,\n",
    "    'val_split': 0.1,\n",
    "    \n",
    "    # Mixed precision\n",
    "    'use_fp16': True\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "CONFIG['output_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c41726f",
   "metadata": {},
   "source": [
    "## 3. Data Loaders (Ontology, Sequences, Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OntologyLoader:\n",
    "    \"\"\"Load GO ontology and build aspect mappings.\"\"\"\n",
    "    \n",
    "    def __init__(self, obo_path: str):\n",
    "        self.obo_path = obo_path\n",
    "        self.term_to_aspect = {}\n",
    "        self.aspect_terms = {\"MF\": set(), \"BP\": set(), \"CC\": set()}\n",
    "        self._load()\n",
    "    \n",
    "    def _load(self):\n",
    "        current_id = None\n",
    "        current_namespace = None\n",
    "        namespace_map = {\n",
    "            \"molecular_function\": \"MF\",\n",
    "            \"biological_process\": \"BP\", \n",
    "            \"cellular_component\": \"CC\"\n",
    "        }\n",
    "        \n",
    "        with open(self.obo_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"[Term]\"):\n",
    "                    current_id = None\n",
    "                    current_namespace = None\n",
    "                elif line.startswith(\"id: GO:\"):\n",
    "                    current_id = line.split(\"id: \")[1]\n",
    "                elif line.startswith(\"namespace:\"):\n",
    "                    ns = line.split(\"namespace: \")[1]\n",
    "                    current_namespace = namespace_map.get(ns)\n",
    "                    if current_id and current_namespace:\n",
    "                        self.term_to_aspect[current_id] = current_namespace\n",
    "                        self.aspect_terms[current_namespace].add(current_id)\n",
    "        \n",
    "        print(f\"Loaded {len(self.term_to_aspect)} GO terms\")\n",
    "        for asp, terms in self.aspect_terms.items():\n",
    "            print(f\"  {asp}: {len(terms)} terms\")\n",
    "\n",
    "\n",
    "class SequenceLoader:\n",
    "    \"\"\"Load protein sequences from FASTA files.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_fasta(fasta_path: str) -> Dict[str, str]:\n",
    "        sequences = {}\n",
    "        current_id = None\n",
    "        current_seq = []\n",
    "        \n",
    "        with open(fasta_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.startswith('>'):\n",
    "                    if current_id:\n",
    "                        sequences[current_id] = ''.join(current_seq)\n",
    "                    current_id = line[1:].split()[0]\n",
    "                    current_seq = []\n",
    "                else:\n",
    "                    current_seq.append(line)\n",
    "            \n",
    "            if current_id:\n",
    "                sequences[current_id] = ''.join(current_seq)\n",
    "        \n",
    "        print(f\"Loaded {len(sequences)} sequences from {Path(fasta_path).name}\")\n",
    "        return sequences\n",
    "\n",
    "\n",
    "class LabelLoader:\n",
    "    \"\"\"Load GO term annotations.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_terms(terms_path: str) -> Dict[str, List[str]]:\n",
    "        protein_terms = {}\n",
    "        \n",
    "        with open(terms_path, 'r') as f:\n",
    "            next(f)  # Skip header\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    protein_id, term = parts[0], parts[1]\n",
    "                    if protein_id not in protein_terms:\n",
    "                        protein_terms[protein_id] = []\n",
    "                    protein_terms[protein_id].append(term)\n",
    "        \n",
    "        print(f\"Loaded annotations for {len(protein_terms)} proteins\")\n",
    "        return protein_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89fdccc",
   "metadata": {},
   "source": [
    "## 4. Load Data and Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96620cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ontology\n",
    "ontology = OntologyLoader(CONFIG['obo_path'])\n",
    "\n",
    "# Load sequences\n",
    "train_sequences = SequenceLoader.load_fasta(CONFIG['train_fasta'])\n",
    "\n",
    "# Load labels\n",
    "protein_terms = LabelLoader.load_terms(CONFIG['train_terms'])\n",
    "\n",
    "# Build vocabulary from training data\n",
    "all_terms = set()\n",
    "for terms in protein_terms.values():\n",
    "    all_terms.update(terms)\n",
    "\n",
    "# Filter to terms in ontology and sort\n",
    "valid_terms = sorted([t for t in all_terms if t in ontology.term_to_aspect])\n",
    "term_to_idx = {t: i for i, t in enumerate(valid_terms)}\n",
    "idx_to_term = {i: t for t, i in term_to_idx.items()}\n",
    "\n",
    "# Build aspect indices\n",
    "aspect_indices = {\"MF\": [], \"BP\": [], \"CC\": []}\n",
    "for term, idx in term_to_idx.items():\n",
    "    aspect = ontology.term_to_aspect[term]\n",
    "    aspect_indices[aspect].append(idx)\n",
    "\n",
    "print(f\"\\nVocabulary: {len(valid_terms)} terms\")\n",
    "for asp, indices in aspect_indices.items():\n",
    "    print(f\"  {asp}: {len(indices)} terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10684efc",
   "metadata": {},
   "source": [
    "## 5. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    \"\"\"Dataset for protein sequences with GO term labels.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        protein_ids: List[str],\n",
    "        sequences: Dict[str, str],\n",
    "        protein_terms: Dict[str, List[str]],\n",
    "        term_to_idx: Dict[str, int],\n",
    "        tokenizer,\n",
    "        max_length: int = 512\n",
    "    ):\n",
    "        self.protein_ids = protein_ids\n",
    "        self.sequences = sequences\n",
    "        self.protein_terms = protein_terms\n",
    "        self.term_to_idx = term_to_idx\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.num_labels = len(term_to_idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.protein_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        protein_id = self.protein_ids[idx]\n",
    "        sequence = self.sequences[protein_id]\n",
    "        \n",
    "        # Truncate sequence if needed\n",
    "        if len(sequence) > self.max_length - 2:  # Account for special tokens\n",
    "            sequence = sequence[:self.max_length - 2]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            sequence,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Build label vector\n",
    "        labels = torch.zeros(self.num_labels, dtype=torch.float32)\n",
    "        if protein_id in self.protein_terms:\n",
    "            for term in self.protein_terms[protein_id]:\n",
    "                if term in self.term_to_idx:\n",
    "                    labels[self.term_to_idx[term]] = 1.0\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': labels,\n",
    "            'protein_id': protein_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90873824",
   "metadata": {},
   "source": [
    "## 6. Model Architecture (Three-Head with Attention Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bdfc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(nn.Module):\n",
    "    \"\"\"Attention-based pooling layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        # hidden_states: (batch, seq_len, hidden)\n",
    "        # attention_mask: (batch, seq_len)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        scores = self.attention(hidden_states).squeeze(-1)  # (batch, seq_len)\n",
    "        \n",
    "        # Mask padding tokens\n",
    "        scores = scores.masked_fill(attention_mask == 0, float('-inf'))\n",
    "        \n",
    "        # Softmax\n",
    "        weights = F.softmax(scores, dim=-1).unsqueeze(-1)  # (batch, seq_len, 1)\n",
    "        \n",
    "        # Weighted sum\n",
    "        pooled = (hidden_states * weights).sum(dim=1)  # (batch, hidden)\n",
    "        \n",
    "        return pooled\n",
    "\n",
    "\n",
    "class ESMThreeHeadModel(nn.Module):\n",
    "    \"\"\"ESM-2 with three separate classification heads (MF, BP, CC).\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        aspect_indices: Dict[str, List[int]],\n",
    "        dropout: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load ESM-2 backbone\n",
    "        self.esm = EsmModel.from_pretrained(model_name)\n",
    "        hidden_size = self.esm.config.hidden_size\n",
    "        \n",
    "        # Store aspect info\n",
    "        self.aspect_indices = aspect_indices\n",
    "        self.num_mf = len(aspect_indices['MF'])\n",
    "        self.num_bp = len(aspect_indices['BP'])\n",
    "        self.num_cc = len(aspect_indices['CC'])\n",
    "        \n",
    "        # Attention pooling\n",
    "        self.attention_pool = AttentionPool(hidden_size)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Three separate heads\n",
    "        self.head_mf = nn.Linear(hidden_size, self.num_mf)\n",
    "        self.head_bp = nn.Linear(hidden_size, self.num_bp)\n",
    "        self.head_cc = nn.Linear(hidden_size, self.num_cc)\n",
    "        \n",
    "        print(f\"Model initialized:\")\n",
    "        print(f\"  Hidden size: {hidden_size}\")\n",
    "        print(f\"  MF head: {self.num_mf} outputs\")\n",
    "        print(f\"  BP head: {self.num_bp} outputs\")\n",
    "        print(f\"  CC head: {self.num_cc} outputs\")\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # Get ESM hidden states\n",
    "        outputs = self.esm(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state  # (batch, seq_len, hidden)\n",
    "        \n",
    "        # Attention pooling\n",
    "        pooled = self.attention_pool(hidden_states, attention_mask)  # (batch, hidden)\n",
    "        pooled = self.dropout(pooled)\n",
    "        \n",
    "        # Three heads\n",
    "        logits_mf = self.head_mf(pooled)  # (batch, num_mf)\n",
    "        logits_bp = self.head_bp(pooled)  # (batch, num_bp)\n",
    "        logits_cc = self.head_cc(pooled)  # (batch, num_cc)\n",
    "        \n",
    "        return {\n",
    "            'MF': logits_mf,\n",
    "            'BP': logits_bp,\n",
    "            'CC': logits_cc\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db997d0",
   "metadata": {},
   "source": [
    "## 7. Asymmetric Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ba730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricLossV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Canonical Asymmetric Loss for multi-label classification.\n",
    "    \n",
    "    Paper: \"Asymmetric Loss For Multi-Label Classification\" (Ridnik et al., 2021)\n",
    "    \n",
    "    Key idea: Down-weight easy negatives more aggressively than positives\n",
    "    to handle extreme class imbalance in multi-label settings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        gamma_neg: float = 4.0,\n",
    "        gamma_pos: float = 1.0,\n",
    "        clip: float = 0.05,\n",
    "        eps: float = 1e-8,\n",
    "        label_smoothing: float = 0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.eps = eps\n",
    "        self.label_smoothing = label_smoothing\n",
    "    \n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            logits: Raw model outputs (batch, num_classes)\n",
    "            targets: Binary labels (batch, num_classes)\n",
    "        \n",
    "        Returns:\n",
    "            Scalar loss\n",
    "        \"\"\"\n",
    "        # Apply label smoothing\n",
    "        if self.label_smoothing > 0:\n",
    "            targets = targets * (1 - self.label_smoothing) + 0.5 * self.label_smoothing\n",
    "        \n",
    "        # Sigmoid\n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs_pos = probs\n",
    "        probs_neg = 1 - probs\n",
    "        \n",
    "        # Asymmetric clipping (shift negatives down)\n",
    "        if self.clip > 0:\n",
    "            probs_neg = (probs_neg + self.clip).clamp(max=1)\n",
    "        \n",
    "        # Focal weights\n",
    "        # For positives: (1 - p)^gamma_pos\n",
    "        # For negatives: p^gamma_neg (after clipping)\n",
    "        weight_pos = (1 - probs_pos) ** self.gamma_pos\n",
    "        weight_neg = probs_pos ** self.gamma_neg\n",
    "        \n",
    "        # Cross entropy components\n",
    "        loss_pos = -targets * weight_pos * torch.log(probs_pos + self.eps)\n",
    "        loss_neg = -(1 - targets) * weight_neg * torch.log(probs_neg + self.eps)\n",
    "        \n",
    "        loss = loss_pos + loss_neg\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea7446d",
   "metadata": {},
   "source": [
    "## 8. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "\n",
    "# Filter to proteins with both sequence and annotations\n",
    "valid_proteins = [\n",
    "    pid for pid in train_sequences.keys()\n",
    "    if pid in protein_terms and len(protein_terms[pid]) > 0\n",
    "]\n",
    "print(f\"Valid proteins: {len(valid_proteins)}\")\n",
    "\n",
    "# Train/val split\n",
    "random.seed(CONFIG['seed'])\n",
    "random.shuffle(valid_proteins)\n",
    "split_idx = int(len(valid_proteins) * (1 - CONFIG['val_split']))\n",
    "train_ids = valid_proteins[:split_idx]\n",
    "val_ids = valid_proteins[split_idx:]\n",
    "\n",
    "print(f\"Train: {len(train_ids)}, Val: {len(val_ids)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ProteinDataset(\n",
    "    protein_ids=train_ids,\n",
    "    sequences=train_sequences,\n",
    "    protein_terms=protein_terms,\n",
    "    term_to_idx=term_to_idx,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "\n",
    "val_dataset = ProteinDataset(\n",
    "    protein_ids=val_ids,\n",
    "    sequences=train_sequences,\n",
    "    protein_terms=protein_terms,\n",
    "    term_to_idx=term_to_idx,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f466bb",
   "metadata": {},
   "source": [
    "## 9. Model, Optimizer, and Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ebc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Initialize model\n",
    "model = ESMThreeHeadModel(\n",
    "    model_name=CONFIG['model_name'],\n",
    "    aspect_indices=aspect_indices,\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = AsymmetricLossV2(\n",
    "    gamma_neg=CONFIG['gamma_neg'],\n",
    "    gamma_pos=CONFIG['gamma_pos'],\n",
    "    clip=CONFIG['clip'],\n",
    "    label_smoothing=CONFIG['label_smoothing']\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "total_steps = len(train_loader) * CONFIG['num_epochs'] // CONFIG['gradient_accumulation']\n",
    "warmup_steps = int(total_steps * CONFIG['warmup_ratio'])\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = GradScaler() if CONFIG['use_fp16'] else None\n",
    "\n",
    "print(f\"\\nTraining setup:\")\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Warmup steps: {warmup_steps}\")\n",
    "print(f\"  Gradient accumulation: {CONFIG['gradient_accumulation']}\")\n",
    "print(f\"  Effective batch size: {CONFIG['batch_size'] * CONFIG['gradient_accumulation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa77ade",
   "metadata": {},
   "source": [
    "## 10. Layer Freezing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a8424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_esm_layers(model: ESMThreeHeadModel, freeze_ratio: float = 0.9):\n",
    "    \"\"\"\n",
    "    Freeze a proportion of ESM layers from the bottom.\n",
    "    \n",
    "    Args:\n",
    "        model: ESMThreeHeadModel instance\n",
    "        freeze_ratio: Proportion of layers to freeze (0.0 = none, 1.0 = all)\n",
    "    \"\"\"\n",
    "    # Get encoder layers\n",
    "    encoder_layers = model.esm.encoder.layer\n",
    "    num_layers = len(encoder_layers)\n",
    "    num_freeze = int(num_layers * freeze_ratio)\n",
    "    \n",
    "    # Freeze embeddings\n",
    "    for param in model.esm.embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Freeze bottom layers\n",
    "    for i in range(num_freeze):\n",
    "        for param in encoder_layers[i].parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze top layers\n",
    "    for i in range(num_freeze, num_layers):\n",
    "        for param in encoder_layers[i].parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Classification heads always trainable\n",
    "    for param in model.attention_pool.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.head_mf.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.head_bp.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.head_cc.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # Count parameters\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"Layer freezing: {num_freeze}/{num_layers} layers frozen\")\n",
    "    print(f\"Trainable params: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")\n",
    "\n",
    "\n",
    "def unfreeze_all(model: ESMThreeHeadModel):\n",
    "    \"\"\"Unfreeze all model parameters.\"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"All layers unfrozen. Trainable params: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0eb83e",
   "metadata": {},
   "source": [
    "## 11. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: ESMThreeHeadModel,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "    aspect_indices: Dict[str, List[int]],\n",
    "    thresholds: Dict[str, float]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model with aspect-specific thresholds.\n",
    "    \n",
    "    Returns dict with per-aspect and overall F1 scores.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = {asp: [] for asp in ['MF', 'BP', 'CC']}\n",
    "    all_labels = {asp: [] for asp in ['MF', 'BP', 'CC']}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            with autocast(enabled=CONFIG['use_fp16']):\n",
    "                logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Extract predictions for each aspect\n",
    "            for asp in ['MF', 'BP', 'CC']:\n",
    "                asp_indices = aspect_indices[asp]\n",
    "                asp_labels = labels[:, asp_indices].cpu().numpy()\n",
    "                asp_probs = torch.sigmoid(logits[asp]).cpu().numpy()\n",
    "                \n",
    "                all_labels[asp].append(asp_labels)\n",
    "                all_preds[asp].append(asp_probs)\n",
    "    \n",
    "    # Concatenate\n",
    "    for asp in ['MF', 'BP', 'CC']:\n",
    "        all_labels[asp] = np.vstack(all_labels[asp])\n",
    "        all_preds[asp] = np.vstack(all_preds[asp])\n",
    "    \n",
    "    # Calculate F1 per aspect\n",
    "    results = {}\n",
    "    f1_scores = []\n",
    "    \n",
    "    for asp in ['MF', 'BP', 'CC']:\n",
    "        thresh = thresholds[asp]\n",
    "        binary_preds = (all_preds[asp] >= thresh).astype(int)\n",
    "        \n",
    "        # Sample-wise F1\n",
    "        f1_samples = []\n",
    "        for i in range(len(binary_preds)):\n",
    "            pred_set = set(np.where(binary_preds[i] == 1)[0])\n",
    "            true_set = set(np.where(all_labels[asp][i] == 1)[0])\n",
    "            \n",
    "            if len(pred_set) == 0 and len(true_set) == 0:\n",
    "                f1_samples.append(1.0)\n",
    "            elif len(pred_set) == 0 or len(true_set) == 0:\n",
    "                f1_samples.append(0.0)\n",
    "            else:\n",
    "                precision = len(pred_set & true_set) / len(pred_set)\n",
    "                recall = len(pred_set & true_set) / len(true_set)\n",
    "                if precision + recall > 0:\n",
    "                    f1_samples.append(2 * precision * recall / (precision + recall))\n",
    "                else:\n",
    "                    f1_samples.append(0.0)\n",
    "        \n",
    "        results[f'{asp}_f1'] = np.mean(f1_samples)\n",
    "        f1_scores.append(results[f'{asp}_f1'])\n",
    "    \n",
    "    # Overall F1 (weighted by aspect)\n",
    "    results['overall_f1'] = np.mean(f1_scores)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c250e9e",
   "metadata": {},
   "source": [
    "## 12. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe28c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'MF_f1': [],\n",
    "    'BP_f1': [],\n",
    "    'CC_f1': [],\n",
    "    'overall_f1': []\n",
    "}\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "# Evaluation thresholds\n",
    "eval_thresholds = CONFIG['thresholds'].copy()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING START\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Layer freezing schedule\n",
    "    if epoch == 0:\n",
    "        freeze_esm_layers(model, freeze_ratio=CONFIG['freeze_ratio'])\n",
    "    elif epoch == 1 and CONFIG['freeze_ratio'] > 0:\n",
    "        unfreeze_all(model)\n",
    "        # Reduce learning rate when unfreezing\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = CONFIG['learning_rate'] * 0.5\n",
    "        print(f\"LR reduced to {CONFIG['learning_rate'] * 0.5}\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for step, batch in enumerate(pbar):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        with autocast(enabled=CONFIG['use_fp16']):\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute loss for each head\n",
    "            loss_mf = criterion(logits['MF'], labels[:, aspect_indices['MF']])\n",
    "            loss_bp = criterion(logits['BP'], labels[:, aspect_indices['BP']])\n",
    "            loss_cc = criterion(logits['CC'], labels[:, aspect_indices['CC']])\n",
    "            \n",
    "            loss = (loss_mf + loss_bp + loss_cc) / 3\n",
    "            loss = loss / CONFIG['gradient_accumulation']\n",
    "        \n",
    "        # Backward pass\n",
    "        if CONFIG['use_fp16']:\n",
    "            scaler.scale(loss).backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        train_loss += loss.item() * CONFIG['gradient_accumulation']\n",
    "        \n",
    "        # Gradient accumulation step\n",
    "        if (step + 1) % CONFIG['gradient_accumulation'] == 0:\n",
    "            if CONFIG['use_fp16']:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{train_loss / (step + 1):.4f}'})\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            with autocast(enabled=CONFIG['use_fp16']):\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                \n",
    "                loss_mf = criterion(logits['MF'], labels[:, aspect_indices['MF']])\n",
    "                loss_bp = criterion(logits['BP'], labels[:, aspect_indices['BP']])\n",
    "                loss_cc = criterion(logits['CC'], labels[:, aspect_indices['CC']])\n",
    "                \n",
    "                loss = (loss_mf + loss_bp + loss_cc) / 3\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    \n",
    "    # Evaluate F1 scores\n",
    "    eval_results = evaluate_model(model, val_loader, device, aspect_indices, eval_thresholds)\n",
    "    \n",
    "    history['MF_f1'].append(eval_results['MF_f1'])\n",
    "    history['BP_f1'].append(eval_results['BP_f1'])\n",
    "    history['CC_f1'].append(eval_results['CC_f1'])\n",
    "    history['overall_f1'].append(eval_results['overall_f1'])\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} Results:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"  MF F1:      {eval_results['MF_f1']:.4f}\")\n",
    "    print(f\"  BP F1:      {eval_results['BP_f1']:.4f}\")\n",
    "    print(f\"  CC F1:      {eval_results['CC_f1']:.4f}\")\n",
    "    print(f\"  Overall F1: {eval_results['overall_f1']:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if eval_results['overall_f1'] > best_f1:\n",
    "        best_f1 = eval_results['overall_f1']\n",
    "        best_epoch = epoch + 1\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_f1': best_f1,\n",
    "            'config': CONFIG,\n",
    "            'term_to_idx': term_to_idx,\n",
    "            'aspect_indices': aspect_indices\n",
    "        }, CONFIG['output_dir'] / 'best_model.pt')\n",
    "        \n",
    "        print(f\"  *** New best model saved! ***\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"TRAINING COMPLETE\")\n",
    "print(f\"Best F1: {best_f1:.4f} at epoch {best_epoch}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d46a0",
   "metadata": {},
   "source": [
    "## 13. Training Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfe715",
   "metadata": {},
   "source": [
    "## 12b. Compare Threshold Configurations\n",
    "\n",
    "Evaluate both threshold sets to determine which performs better:\n",
    "- **Enhanced thresholds**: MF=0.40, BP=0.06, CC=0.30 (aggressive BP)\n",
    "- **KNN-optimal thresholds**: MF=0.40, BP=0.20, CC=0.40 (conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold configurations to compare\n",
    "THRESHOLD_CONFIGS = {\n",
    "    'enhanced': {'MF': 0.40, 'BP': 0.06, 'CC': 0.30},   # Aggressive BP\n",
    "    'knn_optimal': {'MF': 0.40, 'BP': 0.20, 'CC': 0.40}  # Conservative (KNN-tuned)\n",
    "}\n",
    "\n",
    "# Reload best model\n",
    "checkpoint = torch.load(CONFIG['output_dir'] / 'best_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Best model reloaded for threshold comparison\\n\")\n",
    "\n",
    "# Evaluate each threshold configuration\n",
    "threshold_results = {}\n",
    "\n",
    "for config_name, thresholds in THRESHOLD_CONFIGS.items():\n",
    "    print(f\"Evaluating with '{config_name}' thresholds: {thresholds}\")\n",
    "    results = evaluate_model(model, val_loader, device, aspect_indices, thresholds)\n",
    "    threshold_results[config_name] = results\n",
    "    print(f\"  MF: {results['MF_f1']:.4f}, BP: {results['BP_f1']:.4f}, CC: {results['CC_f1']:.4f}\")\n",
    "    print(f\"  Overall F1: {results['overall_f1']:.4f}\\n\")\n",
    "\n",
    "# Comparison table\n",
    "print(\"=\" * 60)\n",
    "print(\"THRESHOLD COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Config':<15} {'MF':<10} {'BP':<10} {'CC':<10} {'Overall':<10}\")\n",
    "print(\"-\" * 55)\n",
    "for config_name, results in threshold_results.items():\n",
    "    print(f\"{config_name:<15} {results['MF_f1']:.4f}     {results['BP_f1']:.4f}     {results['CC_f1']:.4f}     {results['overall_f1']:.4f}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Determine best\n",
    "best_config = max(threshold_results.items(), key=lambda x: x[1]['overall_f1'])\n",
    "print(f\"\\nâœ… Best config: '{best_config[0]}' with F1 = {best_config[1]['overall_f1']:.4f}\")\n",
    "\n",
    "# Store best thresholds for test prediction\n",
    "BEST_THRESHOLDS = THRESHOLD_CONFIGS[best_config[0]]\n",
    "print(f\"   Using thresholds: {BEST_THRESHOLDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1 = axes[0]\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "ax1.plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "ax1.plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Validation Loss', fontsize=14)\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# F1 plot\n",
    "ax2 = axes[1]\n",
    "ax2.plot(epochs_range, history['MF_f1'], 'g-', label='MF F1', linewidth=2, marker='o')\n",
    "ax2.plot(epochs_range, history['BP_f1'], 'b-', label='BP F1', linewidth=2, marker='s')\n",
    "ax2.plot(epochs_range, history['CC_f1'], 'purple', label='CC F1', linewidth=2, marker='^')\n",
    "ax2.plot(epochs_range, history['overall_f1'], 'r-', label='Overall F1', linewidth=2.5, marker='D')\n",
    "ax2.axhline(y=0.2579, color='gray', linestyle='--', label='KNN Baseline', alpha=0.7)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('F1 Score', fontsize=12)\n",
    "ax2.set_title('Validation F1 Scores by Aspect', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['output_dir'] / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPlot saved to {CONFIG['output_dir'] / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01d0dae",
   "metadata": {},
   "source": [
    "## 14. Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecdadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_TEST_PREDICTIONS = True\n",
    "\n",
    "if GENERATE_TEST_PREDICTIONS:\n",
    "    print(\"Loading best model for test predictions...\")\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(CONFIG['output_dir'] / 'best_model.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Load test sequences\n",
    "    test_fasta = Path(CONFIG['data_dir']) / 'Test' / 'testsuperset.fasta'\n",
    "    test_sequences = SequenceLoader.load_fasta(test_fasta)\n",
    "    test_ids = list(test_sequences.keys())\n",
    "    \n",
    "    print(f\"Test proteins: {len(test_ids)}\")\n",
    "    \n",
    "    # Create test dataset (no labels needed)\n",
    "    class TestDataset(Dataset):\n",
    "        def __init__(self, protein_ids, sequences, tokenizer, max_length):\n",
    "            self.protein_ids = protein_ids\n",
    "            self.sequences = sequences\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.protein_ids)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            protein_id = self.protein_ids[idx]\n",
    "            sequence = self.sequences[protein_id]\n",
    "            \n",
    "            if len(sequence) > self.max_length - 2:\n",
    "                sequence = sequence[:self.max_length - 2]\n",
    "            \n",
    "            encoding = self.tokenizer(\n",
    "                sequence,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'protein_id': protein_id\n",
    "            }\n",
    "    \n",
    "    test_dataset = TestDataset(test_ids, test_sequences, tokenizer, CONFIG['max_length'])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Generate predictions\n",
    "    all_predictions = []\n",
    "    \n",
    "    print(\"Generating predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Test inference\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            protein_ids = batch['protein_id']\n",
    "            \n",
    "            with autocast(enabled=CONFIG['use_fp16']):\n",
    "                logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Convert to probabilities\n",
    "            probs_mf = torch.sigmoid(logits['MF']).cpu().numpy()\n",
    "            probs_bp = torch.sigmoid(logits['BP']).cpu().numpy()\n",
    "            probs_cc = torch.sigmoid(logits['CC']).cpu().numpy()\n",
    "            \n",
    "            # Create full probability vector\n",
    "            for i, pid in enumerate(protein_ids):\n",
    "                full_probs = np.zeros(len(term_to_idx))\n",
    "                full_probs[aspect_indices['MF']] = probs_mf[i]\n",
    "                full_probs[aspect_indices['BP']] = probs_bp[i]\n",
    "                full_probs[aspect_indices['CC']] = probs_cc[i]\n",
    "                \n",
    "                # Store predictions above threshold for each term\n",
    "                # Use BEST_THRESHOLDS from comparison (falls back to CONFIG if not defined)\n",
    "                active_thresholds = BEST_THRESHOLDS if 'BEST_THRESHOLDS' in dir() else CONFIG['thresholds']\n",
    "                for term, idx in term_to_idx.items():\n",
    "                    prob = full_probs[idx]\n",
    "                    asp = ontology.term_to_aspect[term]\n",
    "                    thresh = active_thresholds[asp]\n",
    "                    \n",
    "                    if prob >= thresh:\n",
    "                        all_predictions.append({\n",
    "                            'protein_id': pid,\n",
    "                            'term': term,\n",
    "                            'probability': float(prob),\n",
    "                            'aspect': asp\n",
    "                        })\n",
    "    \n",
    "    # Save predictions\n",
    "    test_pred_df = pd.DataFrame(all_predictions)\n",
    "    test_pred_path = CONFIG['output_dir'] / 'test_predictions.parquet'\n",
    "    test_pred_df.to_parquet(test_pred_path, index=False)\n",
    "    \n",
    "    print(f\"\\nTest predictions saved: {test_pred_path}\")\n",
    "    print(f\"Total predictions: {len(test_pred_df):,}\")\n",
    "    print(f\"Unique proteins: {test_pred_df['protein_id'].nunique():,}\")\n",
    "    print(f\"\\nPredictions by aspect:\")\n",
    "    print(test_pred_df.groupby('aspect').size())\n",
    "else:\n",
    "    print(\"Test prediction generation skipped. Set GENERATE_TEST_PREDICTIONS = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4307e",
   "metadata": {},
   "source": [
    "## 15. Save Metadata and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a790c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(CONFIG['output_dir'] / 'training_history.csv', index=False)\n",
    "\n",
    "# Save metadata for submission pipeline\n",
    "# Use best thresholds from comparison if available\n",
    "active_thresholds = BEST_THRESHOLDS if 'BEST_THRESHOLDS' in dir() else CONFIG['thresholds']\n",
    "\n",
    "metadata = {\n",
    "    'model_name': 'esm_threehead_150M',\n",
    "    'model_path': str(CONFIG['output_dir'] / 'best_model.pt'),\n",
    "    'aspect_specific_f1': {\n",
    "        'MF': history['MF_f1'][best_epoch - 1],\n",
    "        'BP': history['BP_f1'][best_epoch - 1],\n",
    "        'CC': history['CC_f1'][best_epoch - 1]\n",
    "    },\n",
    "    'overall_f1': best_f1,\n",
    "    'best_epoch': best_epoch,\n",
    "    'optimal_thresholds': active_thresholds,\n",
    "    'threshold_comparison': threshold_results if 'threshold_results' in dir() else None,\n",
    "    'config': {k: str(v) if isinstance(v, Path) else v for k, v in CONFIG.items()},\n",
    "    'num_terms': len(term_to_idx),\n",
    "    'architecture': {\n",
    "        'backbone': CONFIG['model_name'],\n",
    "        'pooling': 'attention',\n",
    "        'heads': 3,\n",
    "        'loss': 'AsymmetricLossV2',\n",
    "        'freeze_ratio': CONFIG['freeze_ratio']\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(CONFIG['output_dir'] / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model:          ESM-2 150M Three-Head\")\n",
    "print(f\"Best Epoch:     {best_epoch}\")\n",
    "print(f\"Best F1:        {best_f1:.4f}\")\n",
    "print(f\"  MF F1:        {metadata['aspect_specific_f1']['MF']:.4f}\")\n",
    "print(f\"  BP F1:        {metadata['aspect_specific_f1']['BP']:.4f}\")\n",
    "print(f\"  CC F1:        {metadata['aspect_specific_f1']['CC']:.4f}\")\n",
    "print(f\"KNN Baseline:   0.2579\")\n",
    "print(f\"Improvement:    {(best_f1 - 0.2579) / 0.2579 * 100:+.1f}%\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOutputs saved to: {CONFIG['output_dir']}\")\n",
    "print(f\"  - best_model.pt\")\n",
    "print(f\"  - training_history.csv\")\n",
    "print(f\"  - training_curves.png\")\n",
    "print(f\"  - metadata.json\")\n",
    "if GENERATE_TEST_PREDICTIONS:\n",
    "    print(f\"  - test_predictions.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cafa6)",
   "language": "python",
   "name": "cafa6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
